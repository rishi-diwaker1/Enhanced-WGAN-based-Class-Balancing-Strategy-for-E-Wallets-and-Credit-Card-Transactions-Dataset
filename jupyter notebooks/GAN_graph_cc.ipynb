{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: networkx in /home/girishkk/.local/lib/python3.6/site-packages (2.5.1)\n",
      "Requirement already satisfied: matplotlib in /home/girishkk/.local/lib/python3.6/site-packages (3.3.4)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /home/girishkk/.local/lib/python3.6/site-packages (from networkx) (4.4.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/girishkk/.local/lib/python3.6/site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /home/girishkk/.local/lib/python3.6/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /home/girishkk/.local/lib/python3.6/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/girishkk/.local/lib/python3.6/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.15 in /home/girishkk/.local/lib/python3.6/site-packages (from matplotlib) (1.19.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/girishkk/.local/lib/python3.6/site-packages (from matplotlib) (8.4.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/girishkk/.local/lib/python3.6/site-packages (from python-dateutil>=2.1->matplotlib) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girishkk/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing and Label Encoding\n",
    "def df_label_encoder(df, columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset and extract features for node creation\n",
    "def preprocess(df):\n",
    "    # Encode categorical columns\n",
    "    df = df_label_encoder(df, ['merchant', 'category', 'city', 'state', 'job'])\n",
    "\n",
    "    # Normalize the 'amt' and other numeric columns\n",
    "    df['amt'] = (df['amt'] - df['amt'].min()) / (df['amt'].max() - df['amt'].min())\n",
    "\n",
    "    # Combine columns to create unique identifiers for nodes\n",
    "    df['node_from'] = df['cc_num'].astype(str)  # Treat credit card numbers as nodes\n",
    "    df['node_to'] = df['merchant'].astype(str)  # Merchants as another set of nodes\n",
    "\n",
    "    # Sort values by 'node_from' for consistency\n",
    "    df = df.sort_values(by=['node_from'])\n",
    "\n",
    "    # Create a list of unique nodes (accounts/merchants)\n",
    "    node_list = pd.concat([df['node_from'], df['node_to']]).unique()\n",
    "\n",
    "    return df, node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Create Graph Data Without torch_geometric\n",
    "def create_graph_data(df, node_list):\n",
    "    # Create a mapping of node names to indices\n",
    "    node_map = {node: idx for idx, node in enumerate(node_list)}\n",
    "\n",
    "    # Convert edges to indices\n",
    "    edge_index = np.array([\n",
    "        [node_map[from_node], node_map[to_node]] for from_node, to_node in zip(df['node_from'], df['node_to'])\n",
    "    ], dtype=np.int64).T\n",
    "\n",
    "    # Node features (converted to numpy array or tensor)\n",
    "    node_features = torch.tensor(df[['amt', 'category', 'city', 'state']].values, dtype=torch.float)\n",
    "\n",
    "    # Labels (0 for non-fraud, 1 for fraud)\n",
    "    labels = torch.tensor(df['is_fraud'].values, dtype=torch.long)\n",
    "\n",
    "    return node_features, edge_index, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and preprocess\n",
    "df = pd.read_csv('creditcard/fraudTrain.csv')  # Update with your .csv file path\n",
    "df, node_list = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph dataset\n",
    "node_features, edge_index, labels = create_graph_data(df, node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(y_data, title):\n",
    "    classes, counts = torch.unique(y_data, return_counts=True)\n",
    "    plt.bar(classes.numpy(), counts.numpy())\n",
    "    plt.title(title)\n",
    "    plt.xticks([0, 1], ['Non-Fraud', 'Fraud'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot initial class distribution\n",
    "plot_class_distribution(labels, \"Class Distribution Before Augmentation - Credit Card Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = torch.relu(self.fc1(z))\n",
    "        return torch.sigmoid(self.fc2(z))\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return torch.sigmoid(self.fc2(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAN parameters\n",
    "input_size = node_features.shape[1]  # Number of node features\n",
    "hidden_size = 128\n",
    "output_size = input_size  # Output size matches input for node features\n",
    "latent_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize GAN components\n",
    "generator = Generator(latent_size, hidden_size, output_size)\n",
    "discriminator = Discriminator(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.001)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute statistics: mean, variance, and standard deviation\n",
    "def compute_statistics(features):\n",
    "    mean = torch.mean(features, dim=0)\n",
    "    var = torch.var(features, dim=0)\n",
    "    std = torch.std(features, dim=0)\n",
    "    return mean, var, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Mean: tensor([2.3957e-03, 6.2278e+00, 4.4526e+02, 2.6677e+01]), Initial Variance: tensor([3.0670e-05, 1.5315e+01, 6.6874e+04, 2.0538e+02]), Initial Std Dev: tensor([5.5381e-03, 3.9134e+00, 2.5860e+02, 1.4331e+01])\n"
     ]
    }
   ],
   "source": [
    "# Print initial statistics\n",
    "initial_mean, initial_var, initial_std = compute_statistics(node_features)\n",
    "print(f\"Initial Mean: {initial_mean}, Initial Variance: {initial_var}, Initial Std Dev: {initial_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "target_minority_class = torch.sum(labels == 0)  # We want to match the majority class count\n",
    "real_data = node_features[labels == 1]  # Fraud samples (minority class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/10], Loss D: 38.289794921875, Loss G: 0.6087443828582764\n",
      "Epoch [1/10], Loss D: 28.794511795043945, Loss G: 0.606468915939331\n",
      "Epoch [2/10], Loss D: 19.58536148071289, Loss G: 0.6048112511634827\n",
      "Epoch [3/10], Loss D: 10.982868194580078, Loss G: 0.602719247341156\n",
      "Epoch [4/10], Loss D: 3.844224214553833, Loss G: 0.6006903648376465\n",
      "Epoch [5/10], Loss D: 0.8552053570747375, Loss G: 0.5999202728271484\n",
      "Epoch [6/10], Loss D: 0.7997614741325378, Loss G: 0.6003209352493286\n",
      "Epoch [7/10], Loss D: 0.798646867275238, Loss G: 0.6012616753578186\n",
      "Epoch [8/10], Loss D: 0.7967071533203125, Loss G: 0.6033711433410645\n",
      "Epoch [9/10], Loss D: 0.7944555878639221, Loss G: 0.6057661771774292\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    # Update current minority count during each epoch to reflect balancing progress\n",
    "    current_minority_count = torch.sum(labels == 1)\n",
    "    if current_minority_count >= target_minority_class:\n",
    "        break  # Stop training when the minority class is balanced\n",
    "\n",
    "    # Sample noise for generator input\n",
    "    z = torch.randn(real_data.size(0), latent_size)\n",
    "\n",
    "    # Generate fake data\n",
    "    fake_data = generator(z)\n",
    "\n",
    "    # Train Discriminator\n",
    "    d_real = discriminator(real_data)\n",
    "    d_fake = discriminator(fake_data.detach())\n",
    "    loss_d = loss_fn(d_real, torch.ones_like(d_real)) + loss_fn(d_fake, torch.zeros_like(d_fake))\n",
    "    optimizer_d.zero_grad()\n",
    "    loss_d.backward()\n",
    "    optimizer_d.step()\n",
    "\n",
    "    # Train Generator\n",
    "    d_fake = discriminator(fake_data)\n",
    "    loss_g = loss_fn(d_fake, torch.ones_like(d_fake))\n",
    "    optimizer_g.zero_grad()\n",
    "    loss_g.backward()\n",
    "    optimizer_g.step()\n",
    "\n",
    "    # Update your labels based on newly generated samples (for example, appending new data)\n",
    "    labels = torch.cat((labels, torch.zeros(fake_data.size(0), dtype=torch.long)))\n",
    "    node_features = torch.cat((node_features, fake_data))\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss D: {loss_d.item()}, Loss G: {loss_g.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate enough samples to match the class distribution\n",
    "num_generated_samples = target_minority_class - current_minority_count\n",
    "generated_data = generator(torch.randn(num_generated_samples, latent_size))  # Generate samples\n",
    "y_generated = torch.ones(num_generated_samples, dtype=torch.long)  # Label these as fraudulent (minority class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine generated data with the original data\n",
    "x_augmented = torch.cat([node_features, generated_data], dim=0)\n",
    "y_augmented = torch.cat([labels, y_generated], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot augmented class distribution\n",
    "plot_class_distribution(y_augmented, \"Class Distribution After Augmentation - Credit Card Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mean: tensor([  0.2987,   3.3426, 217.8891,  13.3592], grad_fn=<MeanBackward1>), Final Variance: tensor([8.5516e-02, 1.5441e+01, 8.2091e+04, 2.6989e+02],\n",
      "       grad_fn=<VarBackward0>), Final Std Dev: tensor([  0.2924,   3.9295, 286.5156,  16.4282], grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print final statistics\n",
    "final_mean, final_var, final_std = compute_statistics(x_augmented)\n",
    "print(f\"Final Mean: {final_mean}, Final Variance: {final_var}, Final Std Dev: {final_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming real_data is your actual node features labeled as fraud (real minority class)\n",
    "real_data = node_features[labels == 1]  # Take only fraud samples (minority class)\n",
    "\n",
    "# If generated_data has more samples than real_data, we need to match their size\n",
    "min_size = min(real_data.size(0), generated_data.size(0))\n",
    "\n",
    "# Subsample real and generated data to have the same number of rows\n",
    "real_data_sampled = real_data[:min_size]\n",
    "generated_data_sampled = generated_data[:min_size]\n",
    "\n",
    "# Function to compute R-squared\n",
    "def r_squared(real_data, generated_data):\n",
    "    ss_res = torch.sum((real_data - generated_data) ** 2, dim=0)  # Residual sum of squares\n",
    "    ss_tot = torch.sum((real_data - torch.mean(real_data, dim=0)) ** 2, dim=0)  # Total sum of squares\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for each feature: tensor([-1774.8032,    -3.1311,    -2.8761,    -3.4169],\n",
      "       grad_fn=<RsubBackward1>)\n",
      "Mean R-squared: -446.0568542480469\n"
     ]
    }
   ],
   "source": [
    "# Compute R-squared between the real and generated data samples\n",
    "r2_scores = r_squared(real_data_sampled, generated_data_sampled)\n",
    "print(f\"R-squared for each feature: {r2_scores}\")\n",
    "print(f\"Mean R-squared: {r2_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-e763c46865e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0md_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Detach to prevent backprop through the generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_real\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_fake\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mloss_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Backprop for discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0moptimizer_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, confusion_matrix, accuracy_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Split data into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_augmented, y_augmented, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define a simple classifier (e.g., a neural network) for demonstration\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return torch.sigmoid(self.fc2(x))\n",
    "\n",
    "# Initialize model, loss function, and optimizer\n",
    "model = SimpleNN(input_size=node_features.shape[1], hidden_size=64)\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the classifier and track metrics\n",
    "epochs = 50\n",
    "train_losses, test_losses, train_accuracies, test_accuracies = [], [], [], []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    current_minority_count = torch.sum(labels == 1)\n",
    "    if current_minority_count >= target_minority_class:\n",
    "        break\n",
    "\n",
    "    # Generate fake data\n",
    "    z = torch.randn(real_data.size(0), latent_size)\n",
    "    fake_data = generator(z)\n",
    "\n",
    "    # Train Discriminator\n",
    "    optimizer_d.zero_grad()\n",
    "    d_real = discriminator(real_data)\n",
    "    d_fake = discriminator(fake_data.detach())  # Detach to prevent backprop through the generator\n",
    "    loss_d = loss_fn(d_real, torch.ones_like(d_real)) + loss_fn(d_fake, torch.zeros_like(d_fake))\n",
    "    loss_d.backward()  # Backprop for discriminator\n",
    "    optimizer_d.step()\n",
    "\n",
    "    # Train Generator\n",
    "    optimizer_g.zero_grad()\n",
    "    d_fake = discriminator(fake_data)  # Fresh forward pass for generator\n",
    "    loss_g = loss_fn(d_fake, torch.ones_like(d_fake))\n",
    "    loss_g.backward(retain_graph=True)  # Retain graph if needed for further generator computations\n",
    "    optimizer_g.step()\n",
    "\n",
    "    labels = torch.cat((labels, torch.zeros(fake_data.size(0), dtype=torch.long)))\n",
    "    node_features = torch.cat((node_features, fake_data))\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss D: {loss_d.item()}, Loss G: {loss_g.item()}')\n",
    "\n",
    "\n",
    "# Plotting Training and Testing Losses\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.title('Train and Test Loss over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting Training and Testing Accuracies\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_accuracies, label='Train Accuracy')\n",
    "plt.plot(test_accuracies, label='Test Accuracy')\n",
    "plt.title('Train and Test Accuracy over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# ROC AUC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, y_test_pred.detach().numpy())\n",
    "roc_auc = roc_auc_score(y_test, y_test_pred.detach().numpy())\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "y_pred_classes = y_test_pred.round().detach().numpy()\n",
    "cm = confusion_matrix(y_test, y_pred_classes)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Fraud', 'Fraud'], yticklabels=['Non-Fraud', 'Fraud'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Print final AUC score and accuracy\n",
    "print(f\"Final Test ROC AUC Score: {roc_auc:.4f}\")\n",
    "print(f\"Final Test Accuracy: {test_accuracies[-1]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
