{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girishkk/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing and Label Encoding\n",
    "def df_label_encoder(df, columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset and extract features for node creation\n",
    "def preprocess(df):\n",
    "    df = df_label_encoder(df, ['merchant', 'category', 'city', 'state', 'job'])\n",
    "    df['amt'] = (df['amt'] - df['amt'].min()) / (df['amt'].max() - df['amt'].min())\n",
    "    df['node_from'] = df['cc_num'].astype(str)\n",
    "    df['node_to'] = df['merchant'].astype(str)\n",
    "    df = df.sort_values(by=['node_from'])\n",
    "    node_list = pd.concat([df['node_from'], df['node_to']]).unique()\n",
    "    return df, node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_data(df, node_list):\n",
    "    # Create a mapping of node names to indices\n",
    "    node_map = {node: idx for idx, node in enumerate(node_list)}\n",
    "    \n",
    "    # Convert edges to indices\n",
    "    edge_index = np.array([\n",
    "        [node_map[from_node], node_map[to_node]] for from_node, to_node in zip(df['node_from'], df['node_to'])\n",
    "    ], dtype=np.int64).T  # Transpose to get the shape [2, num_edges]\n",
    "\n",
    "    # Node features (converted to numpy array or tensor)\n",
    "    node_features = torch.tensor(df[['amt', 'category', 'city', 'state']].values, dtype=torch.float)\n",
    "\n",
    "    # Labels (0 for non-fraud, 1 for fraud)\n",
    "    labels = torch.tensor(df['is_fraud'].values, dtype=torch.long)\n",
    "\n",
    "    return node_features, edge_index, labels, node_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and preprocess\n",
    "df = pd.read_csv('creditcard/fraudTrain.csv')  # Update with your .csv file path\n",
    "df, node_list = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph dataset\n",
    "node_features, edge_index, labels, node_map = create_graph_data(df, node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "def plot_class_distribution(y_data, title):\n",
    "    classes, counts = torch.unique(y_data, return_counts=True)\n",
    "    plt.bar(classes.numpy(), counts.numpy())\n",
    "    plt.title(title)\n",
    "    plt.xticks([0, 1], ['Non-Fraud', 'Fraud'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot initial class distribution\n",
    "plot_class_distribution(labels, \"Class Distribution Before Augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adjacency_matrix(edge_index, num_nodes):\n",
    "    \"\"\"Build a sparse adjacency matrix from edge indices.\"\"\"\n",
    "    # Convert edge_index to long tensors\n",
    "    row_indices = edge_index[0].long()  # Ensure indices are of type long\n",
    "    col_indices = edge_index[1].long()\n",
    "\n",
    "    # Create a sparse adjacency matrix\n",
    "    adj = torch.sparse_coo_tensor(\n",
    "        torch.stack([row_indices, col_indices]),  # Indices of non-zero elements\n",
    "        torch.ones(row_indices.size(0)),  # Values (unweighted)\n",
    "        (num_nodes, num_nodes)  # Shape of the matrix\n",
    "    )\n",
    "\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_adjacency_matrix(adj, new_nodes_count):\n",
    "    \"\"\"\n",
    "    Expands the adjacency matrix to accommodate new nodes by adding rows and columns for the new nodes.\n",
    "    Assumes no initial edges for the new nodes, i.e., they start with no connections.\n",
    "    \"\"\"\n",
    "    num_existing_nodes = adj.shape[0]\n",
    "    new_size = num_existing_nodes + new_nodes_count\n",
    "    \n",
    "    # Expand the adjacency matrix with zeros for new nodes (initially, no edges for new nodes)\n",
    "    expanded_adj = torch.zeros(new_size, new_size)\n",
    "    \n",
    "    # Copy the old adjacency matrix to the top-left corner of the expanded one\n",
    "    expanded_adj[:num_existing_nodes, :num_existing_nodes] = adj\n",
    "    \n",
    "    return expanded_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def normalize_adj(adj):\n",
    "    # Check if adj is a sparse tensor\n",
    "    if adj.is_sparse:\n",
    "        # Convert sparse tensor to dense\n",
    "        adj = adj.to_dense()\n",
    "    \n",
    "    # Calculate the degree of each node\n",
    "    degree = adj.sum(dim=1)  # Shape: (num_nodes,)\n",
    "    degree_inv_sqrt = degree.pow(-0.5)  # Shape: (num_nodes,)\n",
    "    degree_inv_sqrt[degree_inv_sqrt == float('inf')] = 0  # Handle division by zero\n",
    "\n",
    "    # Normalize the adjacency matrix\n",
    "    degree_inv_sqrt = degree_inv_sqrt.view(-1, 1)  # Reshape to (num_nodes, 1)\n",
    "    adj_normalized = adj.mul(degree_inv_sqrt).mul(degree_inv_sqrt.t())  # Shape: (num_nodes, num_nodes)\n",
    "\n",
    "    return adj_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement GCN layer manually\n",
    "class SimpleGCNLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleGCNLayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        x = torch.relu(self.fc(adj @ x))  # Graph convolution using dense adjacency matrix\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # Graph convolution: x' = ReLU(Adjacency_matrix * x * Weights)\n",
    "        x = torch.matmul(adj, x)  # Multiply adjacency matrix by input feature matrix\n",
    "        x = self.fc(x)  # Apply the linear transformation (weights)\n",
    "        return torch.relu(x)  # Apply ReLU activation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANGeneratorWithManualGCN(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, output_size, num_nodes, edge_index):\n",
    "        super(WGANGeneratorWithManualGCN, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.fc1 = nn.Linear(latent_size, hidden_size)\n",
    "        self.gcn1 = GCNLayer(hidden_size, hidden_size)  # GCN Layer 1\n",
    "        self.gcn2 = GCNLayer(hidden_size, hidden_size)  # GCN Layer 2\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.adj = self.build_sparse_adjacency_matrix(edge_index, num_nodes)  # Build adjacency matrix once in the constructor\n",
    "        self.num_nodes = num_nodes  # Total number of nodes in the graph\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Pass through the first fully connected layer\n",
    "        z = torch.relu(self.fc1(z))\n",
    "\n",
    "        # Use the precomputed adjacency matrix\n",
    "        adj = self.adj\n",
    "        z = z[:self.num_nodes]  # Adjust size of z to match the number of nodes\n",
    "        \n",
    "        # Pass through GCN layers\n",
    "        z = self.gcn1(z, adj)  # Graph convolution using the adjacency matrix\n",
    "        z = self.gcn2(z, adj)\n",
    "        \n",
    "        # Final output layer\n",
    "        return self.fc2(z)\n",
    "\n",
    "    def build_sparse_adjacency_matrix(self, edge_index, num_nodes):\n",
    "        # Ensure edge_index is a LongTensor\n",
    "        if isinstance(edge_index, torch.Tensor):\n",
    "            edge_index = edge_index.long()\n",
    "        else:\n",
    "            raise ValueError(\"edge_index should be a torch.Tensor\")\n",
    "\n",
    "        # Create the sparse adjacency matrix\n",
    "        values = torch.ones(edge_index.shape[1], dtype=torch.float)  # Use ones for unweighted edges\n",
    "        adj_sparse = torch.sparse_coo_tensor(edge_index, values, (num_nodes, num_nodes))\n",
    "        return adj_sparse\n",
    "\n",
    "    def normalize_sparse_adj(self, adj):\n",
    "        # Compute degree matrix\n",
    "        degree = torch.sparse.sum(adj, dim=1).to_dense()\n",
    "        degree_inv_sqrt = torch.pow(degree, -0.5)\n",
    "        degree_inv_sqrt[torch.isinf(degree_inv_sqrt)] = 0  # Avoid division by zero\n",
    "\n",
    "        # Apply normalization: D^(-1/2) * A * D^(-1/2)\n",
    "        adj_normalized = adj.coalesce()  # Ensures indices are sorted, necessary for sparse tensor operations\n",
    "        adj_normalized = adj_normalized * degree_inv_sqrt.unsqueeze(0) * degree_inv_sqrt.unsqueeze(1)\n",
    "        return adj_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size=4, hidden_size=64):\n",
    "        super(WGANDiscriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)  # Input layer expects 4 features\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)  # Hidden layer\n",
    "        self.fc3 = nn.Linear(hidden_size, 1)  # Output layer produces a single output\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))  # First fully connected layer\n",
    "        x = torch.relu(self.fc2(x))  # Second fully connected layer\n",
    "        x = self.fc3(x)  # Output\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 100\n",
    "hidden_size = 64\n",
    "input_size = 1676\n",
    "output_size = 1676\n",
    "num_nodes = 1676"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_to_edge_index(adj):\n",
    "    # Get the indices of non-zero elements (i.e., the edges)\n",
    "    edge_index = adj.nonzero(as_tuple=False).t()\n",
    "    return edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_dense = torch.rand(num_nodes, num_nodes)  # Random dense adjacency matrix for demonstration\n",
    "adj_dense[adj_dense < 0.5] = 0  # Making it sparse by zeroing some elements\n",
    "adj_dense = adj_dense > 0  # Convert to binary (0s and 1s)\n",
    "\n",
    "# Convert to edge index\n",
    "edge_index = dense_to_edge_index(adj_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build and normalize adjacency matrix\n",
    "adj = build_adjacency_matrix(edge_index, num_nodes)\n",
    "adj = normalize_adj(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = dense_to_edge_index(adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of adj: torch.Size([2, 1404899])\n"
     ]
    }
   ],
   "source": [
    "# Assuming adj is your adjacency matrix tensor\n",
    "print(f\"Shape of adj: {adj.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = WGANGeneratorWithManualGCN(latent_size, hidden_size, output_size, num_nodes, edge_index)\n",
    "discriminator = WGANDiscriminator(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0001)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute statistics: mean, variance, and standard deviation\n",
    "def compute_statistics(features):\n",
    "    mean = torch.mean(features, dim=0)\n",
    "    var = torch.var(features, dim=0)\n",
    "    std = torch.std(features, dim=0)\n",
    "    return mean, var, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Mean: tensor([2.3957e-03, 6.2278e+00, 4.4526e+02, 2.6677e+01]), Initial Variance: tensor([3.0670e-05, 1.5315e+01, 6.6874e+04, 2.0538e+02]), Initial Std Dev: tensor([5.5381e-03, 3.9134e+00, 2.5860e+02, 1.4331e+01])\n"
     ]
    }
   ],
   "source": [
    "# Print initial statistics\n",
    "initial_mean, initial_var, initial_std = compute_statistics(node_features)\n",
    "print(f\"Initial Mean: {initial_mean}, Initial Variance: {initial_var}, Initial Std Dev: {initial_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with early stopping\n",
    "num_epochs = 1\n",
    "target_minority_class = torch.sum(labels == 0)\n",
    "real_data = node_features[labels == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "best_loss_d = float('inf')\n",
    "patience = 1\n",
    "trigger_times = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fake_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-9c2597e3074f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Expand the adjacency matrix to accommodate the new fake nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0madj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpand_adjacency_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfake_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Concatenate the new fake data to node_features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Add labels for fake nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'fake_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Expand the adjacency matrix to accommodate the new fake nodes\n",
    "adj = expand_adjacency_matrix(adj, fake_data.size(0))\n",
    "\n",
    "# Concatenate the new fake data to node_features\n",
    "labels = torch.cat((labels, torch.zeros(fake_data.size(0), dtype=torch.long)))  # Add labels for fake nodes\n",
    "node_features = torch.cat((node_features, fake_data))\n",
    "\n",
    "# Debugging prints to check the updated adjacency matrix and node features\n",
    "print(f'Adjacency Matrix Shape after expansion: {adj.shape}')\n",
    "print(f'Node Features Shape after concatenation: {node_features.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    current_minority_count = torch.sum(labels == 1)\n",
    "    if current_minority_count >= target_minority_class:\n",
    "        break\n",
    "\n",
    "    # Update the discriminator\n",
    "    for _ in range(1):\n",
    "        z = torch.randn(real_data.size(0), latent_size, dtype=torch.float)  # Ensure dtype is float\n",
    "        fake_data = generator(z)\n",
    "\n",
    "        optimizer_d.zero_grad()\n",
    "        print(f'Real Data Shape: {real_data.shape}')\n",
    "\n",
    "        d_real = discriminator(real_data)\n",
    "        print(\"Here\")\n",
    "        d_fake = discriminator(fake_data.detach())\n",
    "        loss_d = -torch.mean(d_real) + torch.mean(d_fake)\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Clip weights\n",
    "        for p in discriminator.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "    # Update the generator\n",
    "    optimizer_g.zero_grad()\n",
    "    fake_data = generator(torch.randn(real_data.size(0), latent_size, dtype=torch.float))  # Ensure dtype is float\n",
    "    loss_g = -torch.mean(discriminator(fake_data))\n",
    "    loss_g.backward()\n",
    "    optimizer_g.step()\n",
    "\n",
    "    # Concatenate the new fake data\n",
    "    labels = torch.cat((labels, torch.zeros(fake_data.size(0), dtype=torch.long)))  # Ensure labels are torch.long\n",
    "    node_features = torch.cat((node_features, fake_data))\n",
    "\n",
    "    # Debugging prints to check the shape of adjacency matrix and node features\n",
    "    print(f'Adjacency Matrix Shape after expansion: {adj.shape}')\n",
    "    print(f'Node Features Shape after concatenation: {node_features.shape}')\n",
    "\n",
    "    # Check if adj and node_features have the same number of nodes\n",
    "    if adj.shape[0] != node_features.shape[0]:\n",
    "        print(\"Here\")\n",
    "        raise RuntimeError(f'Adjacency matrix shape {adj.shape} does not match node features shape {node_features.shape}')\n",
    "\n",
    "    # Early stopping check\n",
    "    if loss_d.item() < best_loss_d:\n",
    "        best_loss_d = loss_d.item()\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "\n",
    "    if trigger_times >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss D: {loss_d.item()}, Loss G: {loss_g.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate enough samples to match the class distribution\n",
    "num_generated_samples = target_minority_class - current_minority_count\n",
    "generated_data = generator(torch.randn(num_generated_samples, latent_size))\n",
    "y_generated = torch.ones(num_generated_samples, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add R-squared calculation function\n",
    "def r_squared(real_data, generated_data):\n",
    "    # Mean of real data\n",
    "    real_mean = torch.mean(real_data, dim=0)\n",
    "    \n",
    "    # Total sum of squares (variance of the real data)\n",
    "    ss_tot = torch.sum((real_data - real_mean) ** 2)\n",
    "    \n",
    "    # Residual sum of squares (difference between real and generated data)\n",
    "    ss_res = torch.sum((real_data - generated_data) ** 2)\n",
    "    \n",
    "    # R-squared calculation\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After augmentation, compute R-squared\n",
    "r2_score = r_squared(real_data, generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine generated data with the original data\n",
    "x_augmented = torch.cat([node_features, generated_data], dim=0)\n",
    "y_augmented = torch.cat([labels, y_generated], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot augmented class distribution\n",
    "plot_class_distribution(y_augmented, \"Class Distribution After Augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final statistics\n",
    "final_mean, final_var, final_std = compute_statistics(x_augmented)\n",
    "print(f\"Final Mean: {final_mean}, Final Variance: {final_var}, Final Std Dev: {final_std}\")\n",
    "print(f\"Final R-squared: {r2_score.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
