{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/16], Loss D: -0.0285, Loss G: 0.0072\n",
      "Epoch [1/16], Loss D: -0.0706, Loss G: 0.0331\n",
      "Epoch [2/16], Loss D: -0.1023, Loss G: 0.0468\n",
      "Epoch [3/16], Loss D: -0.1218, Loss G: 0.0550\n",
      "Epoch [4/16], Loss D: -0.1335, Loss G: 0.0588\n",
      "Epoch [5/16], Loss D: -0.1414, Loss G: 0.0608\n",
      "Epoch [6/16], Loss D: -0.1475, Loss G: 0.0625\n",
      "Epoch [7/16], Loss D: -0.1510, Loss G: 0.0640\n",
      "Epoch [8/16], Loss D: -0.1531, Loss G: 0.0648\n",
      "Epoch [9/16], Loss D: -0.1546, Loss G: 0.0653\n",
      "Epoch [10/16], Loss D: -0.1556, Loss G: 0.0657\n",
      "Epoch [11/16], Loss D: -0.1564, Loss G: 0.0660\n",
      "Epoch [12/16], Loss D: -0.1570, Loss G: 0.0663\n",
      "Epoch [13/16], Loss D: -0.1576, Loss G: 0.0666\n",
      "Epoch [14/16], Loss D: -0.1581, Loss G: 0.0670\n",
      "Epoch [15/16], Loss D: -0.1585, Loss G: 0.0671\n",
      "Epoch 0, Loss: 8.0163, Test Acc: 0.9817\n",
      "Epoch 5, Loss: 0.5159, Test Acc: 0.9971\n",
      "Epoch 10, Loss: 0.5786, Test Acc: 0.9971\n",
      "Epoch 15, Loss: 0.6062, Test Acc: 0.9971\n",
      "Epoch 20, Loss: 0.5930, Test Acc: 0.9971\n",
      "Epoch 25, Loss: 0.5672, Test Acc: 0.9971\n",
      "Final Test Accuracy: 0.9971\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# GraphSAGE Layer implementation\n",
    "class GraphSAGELayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True):\n",
    "        super(GraphSAGELayer, self).__init__()\n",
    "        self.normalize = normalize\n",
    "        self.weight = nn.Linear(in_channels * 2, out_channels, bias=True)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight.weight)\n",
    "        if self.weight.bias is not None:\n",
    "            nn.init.zeros_(self.weight.bias)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Aggregate neighbor features\n",
    "        row, col = edge_index\n",
    "        neighbor_features = x[col]\n",
    "        neighbor_mean = scatter_mean(neighbor_features, row, dim=0, dim_size=x.size(0))\n",
    "        \n",
    "        # Concatenate self features with aggregated neighbor features\n",
    "        out = torch.cat([x, neighbor_mean], dim=1)\n",
    "        out = self.weight(out)\n",
    "        \n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2, dim=1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Modified Generator with GraphSAGE layers\n",
    "class GraphSAGEGenerator(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, output_size, num_layers=2):\n",
    "        super(GraphSAGEGenerator, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.fc_z = nn.Linear(latent_size, hidden_size)\n",
    "        \n",
    "        # GraphSAGE layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_channels = hidden_size if i == 0 else hidden_size\n",
    "            self.conv_layers.append(GraphSAGELayer(in_channels, hidden_size))\n",
    "        \n",
    "        # Output layer\n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        # Transform latent vector\n",
    "        x = self.fc_z(z)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # Apply GraphSAGE layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.conv_layers[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        \n",
    "        # Generate final output\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "# Modified Discriminator with GraphSAGE layers\n",
    "class GraphSAGEDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2):\n",
    "        super(GraphSAGEDiscriminator, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        # GraphSAGE layers\n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        first_layer = GraphSAGELayer(input_size, hidden_size)\n",
    "        self.conv_layers.append(first_layer)\n",
    "        \n",
    "        for i in range(num_layers - 1):\n",
    "            self.conv_layers.append(GraphSAGELayer(hidden_size, hidden_size))\n",
    "        \n",
    "        # Final classification layer\n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Apply GraphSAGE layers\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.conv_layers[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            \n",
    "        # Final classification\n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "    \n",
    "# Add the missing Classifier class\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, 2)  # 2 classes: fraud and non-fraud\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Helper function for GraphSAGE\n",
    "def scatter_mean(src, index, dim=-1, dim_size=None):\n",
    "    if dim_size is None:\n",
    "        dim_size = index.max().item() + 1\n",
    "    \n",
    "    out = torch.zeros((dim_size, src.size(-1)), device=src.device)\n",
    "    count = torch.zeros(dim_size, device=src.device)\n",
    "    \n",
    "    index_expanded = index.unsqueeze(-1).expand(-1, src.size(-1))\n",
    "    out.scatter_add_(0, index_expanded, src)\n",
    "    count.scatter_add_(0, index, torch.ones_like(index, dtype=torch.float))\n",
    "    \n",
    "    count[count == 0] = 1  # Avoid division by zero\n",
    "    count = count.unsqueeze(-1)\n",
    "    \n",
    "    return out / count\n",
    "\n",
    "# Data preprocessing functions (same as before)\n",
    "def df_label_encoder(df, columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df_label_encoder(df, ['merchant', 'category', 'city', 'state', 'job'])\n",
    "    df['amt'] = (df['amt'] - df['amt'].min()) / (df['amt'].max() - df['amt'].min())\n",
    "    df['node_from'] = df['cc_num'].astype(str)\n",
    "    df['node_to'] = df['merchant'].astype(str)\n",
    "    df = df.sort_values(by=['node_from'])\n",
    "    node_list = pd.concat([df['node_from'], df['node_to']]).unique()\n",
    "    return df, node_list\n",
    "\n",
    "def create_graph_data(df, node_list):\n",
    "    node_map = {node: idx for idx, node in enumerate(node_list)}\n",
    "    edge_index = np.array([\n",
    "        [node_map[from_node], node_map[to_node]] \n",
    "        for from_node, to_node in zip(df['node_from'], df['node_to'])\n",
    "    ], dtype=np.int64).T\n",
    "    \n",
    "    node_features = torch.tensor(df[['amt', 'category', 'city', 'state']].values, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "    labels = torch.tensor(df['is_fraud'].values, dtype=torch.long)\n",
    "    \n",
    "    return node_features, edge_index, labels\n",
    "\n",
    "# Training parameters\n",
    "def train_wgan_graphsage(generator, discriminator, node_features, edge_index, labels, \n",
    "                        num_epochs=16, batch_size=32, critic_iterations=5):\n",
    "    \n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "    \n",
    "    real_data = node_features[labels == 1]\n",
    "    target_minority_class = torch.sum(labels == 0)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train Discriminator\n",
    "        for _ in range(critic_iterations):\n",
    "            optimizer_d.zero_grad()\n",
    "            \n",
    "            # Real data\n",
    "            d_real = discriminator(real_data, edge_index)\n",
    "            \n",
    "            # Generate fake data\n",
    "            z = torch.randn(real_data.size(0), latent_size)\n",
    "            fake_data = generator(z, edge_index)\n",
    "            d_fake = discriminator(fake_data.detach(), edge_index)\n",
    "            \n",
    "            # Compute WGAN loss\n",
    "            loss_d = -torch.mean(d_real) + torch.mean(d_fake)\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            # Clip weights\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_g.zero_grad()\n",
    "        fake_data = generator(torch.randn(real_data.size(0), latent_size), edge_index)\n",
    "        loss_g = -torch.mean(discriminator(fake_data, edge_index))\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            print(f'Epoch [{epoch}/{num_epochs}], Loss D: {loss_d.item():.4f}, Loss G: {loss_g.item():.4f}')\n",
    "    \n",
    "    return generator, discriminator\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv('creditcard/fraudTrain.csv')\n",
    "    df, node_list = preprocess(df)\n",
    "    node_features, edge_index, labels = create_graph_data(df, node_list)\n",
    "    \n",
    "    # Model parameters\n",
    "    input_size = node_features.shape[1]\n",
    "    hidden_size = 128\n",
    "    latent_size = 64\n",
    "    num_layers = 2\n",
    "    \n",
    "    # Initialize models\n",
    "    generator = GraphSAGEGenerator(latent_size, hidden_size, input_size, num_layers)\n",
    "    discriminator = GraphSAGEDiscriminator(input_size, hidden_size, num_layers)\n",
    "    \n",
    "    # Train models\n",
    "    generator, discriminator = train_wgan_graphsage(\n",
    "        generator, discriminator, node_features, edge_index, labels\n",
    "    )\n",
    "    \n",
    "    # Generate samples\n",
    "    num_samples = torch.sum(labels == 0) - torch.sum(labels == 1)\n",
    "    z = torch.randn(num_samples, latent_size)\n",
    "    with torch.no_grad():  # Add no_grad here for generation\n",
    "        generated_samples = generator(z, edge_index)\n",
    "    \n",
    "    # Combine real and generated data\n",
    "    augmented_features = torch.cat([node_features, generated_samples], dim=0)\n",
    "    augmented_labels = torch.cat([\n",
    "        labels, \n",
    "        torch.ones(num_samples, dtype=torch.long)\n",
    "    ])\n",
    "    \n",
    "    # Split data for classifier training\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        augmented_features.detach(),  # Add detach here\n",
    "        augmented_labels, \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train and evaluate classifier\n",
    "    classifier = Classifier(input_size, hidden_size)\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    # Training loop for classifier\n",
    "    num_epochs = 30\n",
    "    for epoch in range(num_epochs):\n",
    "        classifier.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = classifier(x_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()  # Move zero_grad before loss calculation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluation phase\n",
    "        if epoch % 5 == 0:\n",
    "            classifier.eval()\n",
    "            with torch.no_grad():  # Add no_grad for evaluation\n",
    "                test_outputs = classifier(x_test)\n",
    "                test_loss = criterion(test_outputs, y_test)\n",
    "                accuracy = accuracy_score(\n",
    "                    y_test.cpu().numpy(),\n",
    "                    test_outputs.argmax(dim=1).cpu().numpy()\n",
    "                )\n",
    "                print(f'Epoch {epoch}, Loss: {loss.item():.4f}, Test Acc: {accuracy:.4f}')\n",
    "    \n",
    "    # Final evaluation\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        final_outputs = classifier(x_test)\n",
    "        y_pred = final_outputs.argmax(dim=1)\n",
    "        final_accuracy = accuracy_score(y_test.cpu().numpy(), y_pred.cpu().numpy())\n",
    "        print(f'Final Test Accuracy: {final_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading and preprocessing data...\n",
      "Initializing models...\n",
      "Training WGAN-GP...\n",
      "Epoch [0/16], Loss D: -0.0245, Loss G: 0.0110\n",
      "Epoch [1/16], Loss D: -0.0627, Loss G: 0.0324\n",
      "Epoch [2/16], Loss D: -0.0952, Loss G: 0.0470\n",
      "Epoch [3/16], Loss D: -0.1173, Loss G: 0.0562\n",
      "Epoch [4/16], Loss D: -0.1322, Loss G: 0.0609\n",
      "Epoch [5/16], Loss D: -0.1423, Loss G: 0.0638\n",
      "Epoch [6/16], Loss D: -0.1479, Loss G: 0.0655\n",
      "Epoch [7/16], Loss D: -0.1518, Loss G: 0.0666\n",
      "Epoch [8/16], Loss D: -0.1543, Loss G: 0.0676\n",
      "Epoch [9/16], Loss D: -0.1558, Loss G: 0.0684\n",
      "Epoch [10/16], Loss D: -0.1567, Loss G: 0.0689\n",
      "Epoch [11/16], Loss D: -0.1573, Loss G: 0.0693\n",
      "Epoch [12/16], Loss D: -0.1578, Loss G: 0.0696\n",
      "Epoch [13/16], Loss D: -0.1582, Loss G: 0.0700\n",
      "Epoch [14/16], Loss D: -0.1586, Loss G: 0.0703\n",
      "Epoch [15/16], Loss D: -0.1590, Loss G: 0.0705\n",
      "Generating synthetic samples...\n",
      "Training classifier...\n",
      "Epoch 0, Loss: 0.6851, Test Acc: 0.9971\n",
      "Epoch 5, Loss: 0.5689, Test Acc: 0.9971\n",
      "Epoch 10, Loss: 0.4456, Test Acc: 0.9971\n",
      "Epoch 15, Loss: 0.3759, Test Acc: 0.9971\n",
      "Epoch 20, Loss: 0.3152, Test Acc: 0.9971\n",
      "Epoch 25, Loss: 0.2520, Test Acc: 0.9971\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1gAAAEYCAYAAABBWFftAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABUmUlEQVR4nO3deZyNdf/H8dfHbhBCkW0oKllGJlsqSwsS7alpvevWpl1R7rvtzt0eKeVWSYuolOiXVpFKyZCKVhUiFYos2T+/P76HBjPMMGeumXPez8fjPOac67rmXJ/rmjpfn/P9fj9fc3dERERERERkzxWLOgAREREREZFEoQRLREREREQknyjBEhERERERySdKsERERERERPKJEiwREREREZF8ogRLREREREQknyjBkoRnZq+b2Xn5fWyUzGyemR0ddRwiIiIisi0lWFIomdmqLI/NZvZXltcZeXkvd+/i7k/l97GFUSxB3HKfNpjZ+iyvh+7G+91qZs/u4hgleyIicZaf7WLs/Sab2UW5OK587Byv717kIsmnRNQBiGTH3ctveW5m84CL3P2d7Y8zsxLuvrEgYyvM3L3LludmNgJY6O7/ii4iERHJD7ltF+PgFGAdcIyZVXf3XwrgnIDaeCm61IMlRYqZtTezhWbW18x+AZ40s8pm9n9mtsTM/og9r5Xld7Z+S2dm55vZB2Z2X+zYH82sy24eW8/MppjZSjN7x8yG5NTbk8sY/2NmH8be7y0zq5pl/zlmNt/MlplZ/928d93MbJaZLTezqWbWNMu+vma2KHbub8ysk5l1Bm4Czoh9e/lZHs9X2swGmdnPsccgMysd21c1dg+Wm9nvZva+mRXLKZbduV4RkWRgZsXMrJ+ZfR9rI14ws71j+8qY2bOx7cvNbLqZ7WtmA4AjgIdjn+8P7+QU5wFDgc+Bs7c7d7tYe7LczH4ys/Nj28ua2f2xdmtFrC0tu6UN3+49to6CsDBqYkws5j+B882spZl9FDvHYjN72MxKZfn9Q8zs7Vhb8quZ3WRm1c1sjZlVyXLcobE2uOSe3G+R3FCCJUVRdWBvoC7Qi/Df8ZOx13WAv4CdNRatgG+AqsA9wBNmZrtx7HPAJ0AV4FbgnJ2cMzcxngVcAOwDlAL6AJhZI+DR2PvvFztfLfLAzJoDw4GLY7//P2B8LAk6EOgNHObuFYDjgHnu/gbwX+B5dy/v7s3yck6gP9AaSAOaAS2BLb1p1wELgWrAvoREznOKJY/nFRFJJlcAJwJHEdqIP4AhsX3nARWB2oTP/kuAv9y9P/A+0Dv2+d47uzc2s7pAe2Bk7HHudvteBx4ifJanAbNiu+8DWgBtCe31DcDmXF5PD2AMUCl2zk3ANYR2uA3QCbgsFkMF4B3gjdi1HwBMjPWyTQZOz/K+5wCj3X1DLuMQ2W1KsKQo2gzc4u7r3P0vd1/m7i+5+xp3XwkMIDQ0OZnv7o+5+ybgKaAG4R/5uT7WzOoAhwE3u/t6d/8AGJ/TCXMZ45Pu/q27/wW8QGisAE4F/s/dp7j7OuDf5L6h2qIX8D93n+bum2LzzNYREqBNQGmgkZmVdPd57v59Ht8/OxnA7e7+m7svAW7j7yR0A+Fe1nX3De7+vrt7HGMREUlUlwD93X1hrI24FTjVzEoQPmurAAfEPvtnuPufeXjvc4DP3f1LYDRwSOwLOwhfCr7j7qNin+PL3H1WbDTCP4Cr3H1R7LxTY7Hlxkfu/oq7b4618TPc/WN33+ju8whfEG5pP7sBv7j7/e6+1t1Xuvu02L6niPW4mVlx4EzgmTxcu8huU4IlRdESd1+75YWZpZjZ/2JDEf4EpgCVYh+o2dk6ftzd18Sels/jsfsBv2fZBvBTTgHnMsas49rXZIlpv6zv7e6rgWU5nSsHdYHrYkMslpvZcsI3mvu5+1zgakKj/JuZjTaz/fL4/tnZD5if5fX82DaAe4G5wFtm9oOZ9QOIYywiIomqLjA2y2f7V4Qvq/YlJBRvAqNjQ7XvyeMQuXMJvUi4+yLgPUKvGIQ2JLsvwKoCZXLYlxvbtKVm1jA2pPyXWPv539g5dhYDwDjCl3X1gGOAFe7+yW7GJJInSrCkKPLtXl8HHAi0cve9gCNj23Ma9pcfFgN7m1lKlm21d3L8nsS4OOt7x85ZJefDs/UTMMDdK2V5pLj7KAB3f87d2xEaagfujv3e9vc6L36Ovd8WdWLbiH3LeJ271we6A9dumWu1k1hERGRHPwFdtvt8LxPrPdrg7re5eyPCcL1u/D3Mb6ef72bWFmgA3BhLbn4hDJs/K9Y79hOwfza/uhRYm8O+1cDWdjP2JWO17Y7ZPq5Hga+BBrH28yb+bjt/AupnF3/si9gXCL1Y56DeKylASrAkEVQgzGlaHpvYe0u8T+ju84FM4FYzK2VmbYAT4hTjGKBbbDJxKeB28v7/7mPAJWbWyoJyZna8mVUwswPNrKOFAhRrY3FuGYL4K5AaG/KxMyVjk6m3PEoAo4B/mVk1CwU7bgaeha0FNw6IzWdbQfi2dfMuYhERkR0NBQbE5kQR+8ztEXvewcyaxBKZPwlDBrN+vmebnMScB7wNNCIMWU8DGgNlgS6Enq2jzex0MythZlXMLM3dNxPm/D5gZvuZWXEzaxP7XP8WKBNrf0oS5uWW3sX1VYjFvsrMDgIuzbLv/4AaZnZ1bE5xBTNrlWX/08D5hC/ylGBJgVGCJYlgEOEDfynwMWGya0HIIEy4XQbcATxPmNeUnUHsZozuPge4nFBUYzFhAvPCnf7Sju+RCfyTUFjjD8LwvPNju0sDd8Vi+4VQZOPG2L4XYz+XmdnMnZxiAiEZ2vK4lXBPMgmVp74AZsa2QfhW9B1gFfAR8Ii7T9pFLCIisqMHCXOA3zKzlYQ2ZkuSUZ3wJd2fhKGD7/F3ovEgYa7WH2Y2OOsbmlkZQoGIh9z9lyyPH2O/f567LwC6EkZo/E4ocLGlGFIfwuf+9Ni+u4Fi7r6CUKDicWARoUdrV+1ZH8J8r5WELwuf37IjNqf5GMIXnL8A3wEdsuz/kJBQzox9MSpSICzMKxeRPWVmzwNfu3vce9BERERk18zsXeA5d3886lgkeagHS2Q3mdlhZra/hTVIOhNKy74ScVgiIiJCaKeBQ8nS6yVSEEpEHYBIEVYdeJlQcGIhcKm7fxptSCIiImJmTxHWB7sqNpRQpMBoiKCIiIiIiEg+0RBBERERERGRfFLkhghWrVrVU1NTow5DRETy2YwZM5a6+/Zr4hR5ardERBJTTu1WXBOs2MT/B4HiwOPuftd2+wfydznNFGAfd6+0s/dMTU0lMzMzDtGKiEiUzCwhyyir3RIRSUw5tVtxS7Bii9oNIaxPsBCYbmbj3f3LLce4+zVZjr8CaB6veEREREREROItnnOwWgJz3f0Hd18PjCaUsc7JmcCoOMYjIiIiIiISV/FMsGoCP2V5vTC2bQdmVheoB7ybw/5eZpZpZplLlizJ90BFRERERETyQ2EpctETGOPum7Lb6e7DgGEA6enpqisvInmyYcMGFi5cyNq1a6MORYAyZcpQq1YtSpYsGXUoIiKFgtqpwi2v7VY8E6xFQO0sr2vFtmWnJ3B5HGMRkSS2cOFCKlSoQGpqKmYWdThJzd1ZtmwZCxcupF69elGHIyJSKKidKrx2p92K5xDB6UADM6tnZqUISdT47Q8ys4OAysBHcYxFRJLY2rVrqVKlihqtQsDMqFKlir6lFRHJQu1U4bU77VbcEix33wj0Bt4EvgJecPc5Zna7mXXPcmhPYLS7a+ifiMSNGq3CQ38LEZEd6bOx8Mrr3yauc7DcfQIwYbttN2/3+tZ4xrAnli6Fl1+GU06BKlWijkZERERERAq7eA4RLPJ+/BEuvhjeeCPqSESkKFu2bBlpaWmkpaVRvXp1atasufX1+vXrd/q7mZmZXHnllbs8R9u2bfMl1smTJ9OtW7d8eS8RESka9qSdgtB2TJ06dafHnHjiibRu3Tq/Qi7UCksVwUKpRQuoVg0mTICMjKijEZGiqkqVKsyaNQuAW2+9lfLly9OnT5+t+zdu3EiJEtl/HKenp5Oenr7Lc+yqYRMRkcQx8ouR9J/YnwUrFlCnYh0GdBpARpPd/8fqrtqpXZk8eTLly5fP8cu+5cuXM2PGDMqXL88PP/xA/fr1dzvWndlZe1qQ1IO1E8WKQZcuoQdrU7YF5EVEds/555/PJZdcQqtWrbjhhhv45JNPaNOmDc2bN6dt27Z88803wLY9Srfeeiv/+Mc/aN++PfXr12fw4MFb3698+fJbj2/fvj2nnnoqBx10EBkZGWyZ4jphwgQOOuggWrRowZVXXpmnnqpRo0bRpEkTGjduTN++fQHYtGkT559/Po0bN6ZJkyYMHDgQgMGDB9OoUSOaNm1Kz5499/xmiYjIViO/GEmvV3sxf8V8HGf+ivn0erUXI78Yma/nmTFjBkcddRQtWrTguOOOY/HixcCOn/Hz5s1j6NChDBw4kLS0NN5///0d3uvll1/mhBNOoGfPnowePXrr9rlz53L00UfTrFkzDj30UL7//nsA7r77bpo0aUKzZs3o168fAO3btyczMxOApUuXkpqaCsCIESPo3r07HTt2pFOnTqxatYpOnTpx6KGH0qRJE8aNG7f1fE8//TRNmzalWbNmnHPOOaxcuZJ69eqxYcMGAP78889tXu+u6FO8Qq5rV3j6afjkE2jTJupoRGRPXX01xL6kyzdpaTBoUN5/b+HChUydOpXixYvz559/8v7771OiRAneeecdbrrpJl566aUdfufrr79m0qRJrFy5kgMPPJBLL710h3U5Pv30U+bMmcN+++3H4Ycfzocffkh6ejoXX3wxU6ZMoV69epx55pm5jvPnn3+mb9++zJgxg8qVK3PsscfyyiuvULt2bRYtWsTs2bOB8A0lwF133cWPP/5I6dKlt24TEZHcufqNq5n1y6wc93+88GPWbVq3zbY1G9Zw4bgLeWzGY9n+Tlr1NAZ1HpTrGNydK664gnHjxlGtWjWef/55+vfvz/Dhw3f4jK9UqRKXXHLJTnu9Ro0axc0338y+++7LKaecwk033QRARkYG/fr146STTmLt2rVs3ryZ119/nXHjxjFt2jRSUlL4/fffdxnvzJkz+fzzz9l7773ZuHEjY8eOZa+99mLp0qW0bt2a7t278+WXX3LHHXcwdepUqlatyu+//06FChVo3749r732GieeeCKjR4/m5JNP3uN1GtWDtQvHHgvFi4dhgiIi+em0006jePHiAKxYsYLTTjuNxo0bc8011zBnzpxsf+f444+ndOnSVK1alX322Ydff/11h2NatmxJrVq1KFasGGlpacybN4+vv/6a+vXrb13DIy8J1vTp02nfvj3VqlWjRIkSZGRkMGXKFOrXr88PP/zAFVdcwRtvvMFee+0FQNOmTcnIyODZZ58tFEM1REQSyfbJ1a6279Y51q1j9uzZHHPMMaSlpXHHHXewcOFCIO+f8b/++ivfffcd7dq1o2HDhpQsWZLZs2ezcuVKFi1axEknnQSExXxTUlJ45513uOCCC0hJSQFg77333uU5jjnmmK3HuTs33XQTTZs25eijj2bRokX8+uuvvPvuu5x22mlUrVp1m/e96KKLePLJJwF48sknueCCC/J4t3aklm8XKleGtm1DgvWf/0QdjYjsqd3paYqXcuXKbX3+73//mw4dOjB27FjmzZtH+/bts/2d0qVLb31evHhxNm7cuFvH5IfKlSvz2Wef8eabbzJ06FBeeOEFhg8fzmuvvcaUKVN49dVXGTBgAF988YUSLRGRXNpVT1PqoFTmr5i/w/a6Fesy+fzJ+RKDu3PIIYfw0Uc7LlOb3Wf8zrzwwgv88ccfW7/g+/PPPxk1atTWoX+5VaJECTZv3gyww5pUWdvTkSNHsmTJEmbMmEHJkiVJTU3d6RpWhx9+OPPmzWPy5Mls2rSJxo0b5ymu7KgHKxe6doWZMyE29FREJN+tWLGCmjVrAmE8eX478MAD+eGHH5g3bx4Azz//fK5/t2XLlrz33nssXbqUTZs2MWrUKI466iiWLl3K5s2bOeWUU7jjjjuYOXMmmzdv5qeffqJDhw7cfffdrFixglWrVuX79YiIJKsBnQaQUjJlm20pJVMY0GlAvp2jdOnSLFmyZGuCtWHDBubMmZPjZ3yFChVYuXJltu81atQo3njjDebNm8e8efOYMWMGo0ePpkKFCtSqVYtXXnkFCL1ma9as4ZhjjuHJJ59kzZo1AFuHCKampjJjxgwAxowZk2PsK1asYJ999qFkyZJMmjSJ+fNDMtqxY0defPFFli1bts37Apx77rmcddZZ+dJ7BUqwcqVr1/Dz9dejjUNEEtcNN9zAjTfeSPPmzePS41S2bFkeeeQROnfuTIsWLahQoQIVK1bM9tiJEydSq1atrY958+Zx11130aFDB5o1a0aLFi3o0aMHixYton379qSlpXH22Wdz5513smnTJs4++2yaNGlC8+bNufLKK6lUqVK+X4+ISLLKaJLBsBOGUbdiXQyjbsW6DDth2B5VEdxesWLFGDNmDH379qVZs2akpaUxderUHD/jTzjhBMaOHbtDkYt58+Yxf/78bcqz16tXj4oVKzJt2jSeeeYZBg8eTNOmTWnbti2//PILnTt3pnv37qSnp5OWlsZ9990HQJ8+fXj00Udp3rw5S5cuzfn+ZGSQmZlJkyZNePrppznooIMAOOSQQ+jfvz9HHXUUzZo149prr93md/744488DZ/fGdtSXaqoSE9P9y0VRAqKO9SuDa1bw04SZhEppL766isOPvjgqMOI3KpVqyhfvjzuzuWXX06DBg245pprIoklu7+Jmc1w913XpC9iomi3RKRoUTsVrTFjxjBu3DieeeaZHI/JS7ulQfG5YBZ6sUaPhg0bYA8Li4iIROKxxx7jqaeeYv369TRv3pyLL7446pBEREQidcUVV/D6668zIR8r2inByqWuXeGxx+DDDyGHueciIoXaNddcE1mPlYiISGH00EMP5ft7ag5WLh19dOi5Url2EZGizcyGm9lvZjY7h/1mZoPNbK6ZfW5mh263fy8zW2hmDxdMxCKSDIratJ1kkte/jRKsXCpfHo46Cl57LepIRERkD40AOu9kfxegQezRC3h0u/3/AabEJTIRSUplypRh2bJlSrIKIXdn2bJllClTJte/oyGCedC1K1x7LcybB6mpUUcjIiK7w92nmFnqTg7pATzt4V86H5tZJTOr4e6LzawFsC/wBpBwBTlEJBq1atVi4cKFLFmyJOpQJBtlypShVq1auT5eCVYebEmwXn8dLr006mhERCROagI/ZXm9EKhpZr8C9wNnA0fv7A3MrBeh94s6derEKUwRSRQlS5bcuhCvFH0aIpgHDRtC/fqahyUiebNs2TLS0tJIS0ujevXq1KxZc+vr9evX7/L3J0+ezNSpU7PdN2LECHr37p3fIUv2LgMmuPvCXR3o7sPcPd3d06tVq1YAoYmISGGhBCsPtpRrnzgR1q6NOhoRiZuRI8M44GLFws+RI/fo7apUqcKsWbOYNWsWl1xyCddcc83W16VKldrl7+8swZK4WATUzvK6VmxbG6C3mc0D7gPONbO7Cj48EREpzJRg5VHXrvDXX/Dee1FHIiJxMXIk9OoF8+eHVcbnzw+v9zDJ2t6MGTM46qijaNGiBccddxyLFy8GYPDgwTRq1IimTZvSs2dP5s2bx9ChQxk4cCBpaWm8//77uXr/Bx54gMaNG9O4cWMGDRoEwOrVqzn++ONp1qwZjRs35vnnnwegX79+W8/Zp0+ffL3OImo8IXkyM2sNrHD3xe6e4e513D0V6EOYp9Uv0khFRKTQ0RysPGrfHsqWDcMEjzsu6mhEJM+uvhpmzcp5/8cfw7p1225bswYuvDAshpedtDSIJTG54e5cccUVjBs3jmrVqvH888/Tv39/hg8fzl133cWPP/5I6dKlWb58OZUqVeKSSy6hfPnyuU5+ZsyYwZNPPsm0adNwd1q1asVRRx3FDz/8wH777cdrsXKoK1asYNmyZYwdO5avv/4aM2P58uW5vo6iysxGAe2Bqma2ELgFKAng7kOBCUBXYC6wBrggmkhFRKQoUoKVR2XLQseOoVz7oEFh2KCIJJDtk6tdbd+tU6xj9uzZHHPMMQBs2rSJGjVqANC0aVMyMjI48cQTOfHEE3fr/T/44ANOOukkypUrB8DJJ5/M+++/T+fOnbnuuuvo27cv3bp144gjjmDjxo2UKVOGCy+8kG7dutGtW7d8ucbCzN3P3MV+By7fxTEjCOXeRUREtqEEazd07RoSrO++C4UvRKQI2VVPU2pqGBa4vbp1YfLkfAnB3TnkkEP46KOPdtj32muvMWXKFF599VUGDBjAF198kS/nBGjYsCEzZ85kwoQJ/Otf/6JTp07cfPPNfPLJJ0ycOJExY8bw8MMP8+677+bbOUVERJKN5mDthi5dwk9VExRJQAMGQErKtttSUsL2fFK6dGmWLFmyNcHasGEDc+bMYfPmzfz000906NCBu+++mxUrVrBq1SoqVKjAypUrc/3+RxxxBK+88gpr1qxh9erVjB07liOOOIKff/6ZlJQUzj77bK6//npmzpzJqlWrWLFiBV27dmXgwIF89tln+XadIiIiyUg9WLuhXj04+OCQYF19ddTRiEi+ysgIP/v3hwULoE6dkFxt2Z4PihUrxpgxY7jyyitZsWIFGzdu5Oqrr6Zhw4acffbZrFixAnfnyiuvpFKlSpxwwgmceuqpjBs3joceeogjjjhim/cbMWIEr7zyytbXH3/8Meeffz4tW7YE4KKLLqJ58+a8+eabXH/99RQrVoySJUvy6KOPsnLlSnr06MHatWtxdx544IF8u04REZFkZGGoedGRnp7umZmZUYdBnz7w0EOwbBmULx91NCKyM1999RUHH3xw1GFIFtn9TcxshrunRxRS3BSWdktERPJXTu2Whgjupq5dYf160FQFERERERHZQgnWbmrXDipU0DwsERERERH5mxKs3VSqFBxzTKgmWMRGWYokpaI2HDqR6W8hIiKJTAnWHujaFRYuhNmzo45ERHamTJkyLFu2TP+wLwTcnWXLllGmTJmoQxEREYkLVRHcA1nLtTdpEm0sIpKzWrVqsXDhQpYsWRJ1KEJIeGvVqhV1GCIiInGhBGsP7LcfpKWFBKtv36ijEZGclCxZknr16kUdhoiIiCQBDRHcQ127wocfwvLlUUciIiIiIiJRU4K1h7p2hU2b4O23o45ERERERESiFtcEy8w6m9k3ZjbXzPrlcMzpZvalmc0xs+fiGU88tG4Ne++tcu0iIiIiIhLHOVhmVhwYAhwDLASmm9l4d/8yyzENgBuBw939DzPbJ17xxEvx4nDccSHB2rwZiqlPUEREREQkacWzyEVLYK67/wBgZqOBHsCXWY75JzDE3f8AcPff4hhP3HTtCqNGwcyZkJ6+6+MXL4bHHoP33oO99oIqVcJj7723/Zn1eenS8b8OERERERHZM/FMsGoCP2V5vRBotd0xDQHM7EOgOHCru7+x/RuZWS+gF0CdOnXiEuyeOO44MAu9WDklWO4weTI8+iiMHQsbN0KLFvDbb/DJJ7BsGaxbl/M5ypWDTp3gvPOgW7ew0LGIiIiIiBQuUZdpLwE0ANoDtYApZtbE3ZdnPcjdhwHDANLT0wvdSqHVqkHLliHBuvnmbfetWAFPPx0Sq6++Cj1SV18NF18MBxzw93HusGYN/P57SLaWLdv2+aJFITEbPz68x5lnhmQrPT0kdyIiIiIiEr14JliLgNpZXteKbctqITDN3TcAP5rZt4SEa3oc44qLrl3h1lthyZKQcM2aFZKqZ58NiVPLljBiBJx+OpQtu+Pvm4VeqnLloHbtHfcDDB4cqhU+9RQ8/jgMGQKNGoVE6+yzw7pcIiIiIiISnXiWZJgONDCzemZWCugJjN/umFcIvVeYWVXCkMEf4hhT3HTtGnqhbrwR2raF5s3hmWdCT1NmJkybFhKh7JKr3CpRArp0gdGj4Zdf4H//g4oVwyLHtWtD585h319/5d91iYiIiIhI7sUtwXL3jUBv4E3gK+AFd59jZrebWffYYW8Cy8zsS2AScL27L4tXTPF06KFQvTo88QQsXQoDB4ZhfY8/HuZa5bdKlaBXL5g6Fb75JiR2X34ZEroaNaBPHyVaIiIiIiIFzdwL3ZSmnUpPT/fMzMyow8jW9OmwciW0bx9NufbNm0MhjSeegOeeg8aNQ4/WIYcUfCwiInllZjPcPRe1WIuWwtxuiYjI7sup3dKqTfnosMOgY8fo1sIqViycf+RIeP31UKEwPR2GDg3DF0VEREREJL6UYCWozp3hs8/gyCPh0kvhlFNCVUIREREREYkfJVgJrHr10JN1773wf/8HzZrBlClRRyUiIiIikriUYCW4YsVCwYupU6FMGejQAW65JSx0LCIiIiIi+UsJVpJIT4eZM+Gcc+D220Mhjvnzo45KRERERCSxKMFKIhUqhMWOR46Ezz8PQwZffDHqqEREREREEocSrCR01lkwaxYceCCcfjr885+wdm3UUYmIiIiIFH1KsJJU/frwwQfQr19YDLlrV/jzz6ijEhEREREp2pIrwRo5ElJTQ+WH1NTwOomVLAl33gnPPBOqC3bsCEuWRB2ViIiIiEjRlTwJ1siR0KtXqOzgHn726pX0SRbA2WfDuHEwZw60awcLFkQdkYiIiIhI0ZQ8CVb//rBmzbbb1qwJ24Xjj4e334Zff4W2beHLL6OOSEQkPsxsuJn9Zmazc9hvZjbYzOaa2edmdmhse5qZfWRmc2LbzyjYyEVEpChIngQrp26Z+fPDQlEvvQSLFxdsTIVMu3ZhqODGjXDEEfDJJ1FHJCISFyOAzjvZ3wVoEHv0Ah6NbV8DnOvuh8R+f5CZVYpfmCIiUhQlT4JVp07220uXhocfhlNPhf32g3r1ICMDhgyBTz9NuhV5mzaFDz+EihXDnKx33ok6IhGR/OXuU4Dfd3JID+BpDz4GKplZDXf/1t2/i73Hz8BvQLX4RywiIkVJ8iRYAwZASsq221JS4IknYMUK+OgjeOCBsCLvpEnQuzcceihUqhQyjX/9CyZMgN931iYnhv33D0lW/fqhuuCYMVFHJCJSoGoCP2V5vTC2bSszawmUAr7P7g3MrJeZZZpZ5hJVDxIRSSolog6gwGRkhJ/9+4fhgnXqhKRry/bWrcPjmmtCEYwFC2Dq1JB4TZ0Kd90FmzaFYw86KExU2vI48MBQmTCB1KgB770HJ5wQ1sp69FG4+OKooxIRiZ6Z1QCeAc5z983ZHePuw4BhAOnp6V6A4YmISMSSJ8GCkExtSah2xgzq1g2PM88M21avhunTQ7I1dSq88goMHx72Va4MbdqER9u20LIllC8ft8soKJUrw1tvwWmnwSWXwLJlcOON4faIiCSwRUDtLK9rxbZhZnsBrwH9Y8MHRUREtpFcCdaeKFcO2rcPDwi9XN9++3fC9dFHYQghhN6sZs1CsrUl6UpNLZKZSUpKyCUvuCB0/i1dCvfdl3AddiIiWY0HepvZaKAVsMLdF5tZKWAsYX6WBk+LiEi2lGDtLrMwNPDAA0P2AfDHHzBt2t9J11NPhWIZANWrbzus8NBDQ4GNIqBkSXj6adh7bxg4EP78E4YNU5IlIkWTmY0C2gNVzWwhcAtQEsDdhwITgK7AXELlwNiHPKcDRwJVzOz82Lbz3X1WQcUuIiKFnxKs/FS5MnTuHB4Q5mzNnv13wjV1Krz8cthXqhS0aPF3wtWmTZj4VEgVKwYPPgh77RWmrpUtC4MHF8lOORFJcu5+5i72O3B5NtufBZ6NV1wiIpIYlGDFU/HiYahgs2Zw6aVh26+//l04Y+rUUCL+/vvDvtTUbXu5mjSBEoXnT2QG//kP/PVXKLiYkhJqfyjJEhEREREJCs+/3pPFvvvCiSeGB8C6dWG9rS3zuCZNgueeC/vKlYNWrf6ex9W6dRinFyGzMAdrzRq4554Q4s03RxqSiIiIiEihoQQraqVL/10iHrYtEb8l6cpaIv7gg7ctnrF9ifiRI3MuRZ9PzMLUsr/+gltuCT1Zffrk6ylERERERIokJViFTW5KxI8dGxZIhr9LxLdtG7qVBg4MmQ/A/PnQq1d4ns9JVrFi8Pjj4VTXXx+SrMsuy9dTiIiIiIgUOUqwioJdlYifOvXvEvHbW7Mm9Gjlc4IFYXrYs8/C2rVw+eWh8MWWgooiIiIiIslICVZRlFOJ+CpVQvK1vQUL4hZKyZLw/PPQvTtcdFFIsnr2jNvpREREREQKNa1klCgqVw5zrrKT0/Z8UqZMWIy4XTs4+2wYNy6upxMRERERKbSUYCWSAQPCZKjtbSmgEUcpKfB//wfp6XD66fDmm3E/pYiIiIhIoaMEK5FkZMCwYaFAhlnouWrTJozhGzgw7qevUAFefx0aNQpV6N97L+6nFBEREREpVJRgJZqMDJg3DzZvDlUEp0yBU06Ba6+FRx6J++krV4a33oJ69aBbN/j447ifUkRERESk0FCClehKlAgLF59wQij19/jjcT9ltWowcWJYU7lzZ5g1K+6nFBEREREpFJRgJYNSpeDFF0O206sXPP103E9Zo0ZIsvbaC449Fr7+Ou6nFBERERGJnBKsZFG6NLz8MnTsGEq7P/983E9Zty68805YlPjoo+HHH+N+ShERERGRSCnBSiZly4Ya6ocfHuZqjR0b91M2bBjmZK1ZE5Ksn3+O+ylFRERERCIT1wTLzDqb2TdmNtfM+mWz/3wzW2Jms2KPi+IZjwDlysFrr0HLlnDGGaG2epw1bRqqC/72GxxzDCxdGvdTioiIiIhEIm4JlpkVB4YAXYBGwJlm1iibQ59397TYI/4VGOTveurNmoUKg2+9FfdTtmoFr74KP/wAxx0HK1bE/ZQiIiIiIgUunj1YLYG57v6Du68HRgM94ng+yYuKFcNqwAcfDD16wKRJcT9l+/bw0kvw+edw/PGwenXcTykiIiIiUqDimWDVBH7K8nphbNv2TjGzz81sjJnVzu6NzKyXmWWaWeaSJUviEWty2ntvePtt2H//sGjVBx/E/ZRdu4aq8R99BCedBOvWxf2UIiIiIiIFJuoiF68Cqe7eFHgbeCq7g9x9mLunu3t6tWrVCjTAhFetWij1V6tWyH6mTYv7KU87LSzH9fbb0LMnbNwY91OKiIiIiBSIeCZYi4CsPVK1Ytu2cvdl7r6lD+NxoEUc45GcVK8O774L++wTJkjNnBn3U15wATz4ILzySni+eXPcTykiIiIiEnfxTLCmAw3MrJ6ZlQJ6AuOzHmBmNbK87A58Fcd4ZGdq1gxJVqVKodTf55/H/ZRXXgl33AHPPguXXw7ucT+liCQQMzvBzKIeiSEiIrKNuDVM7r4R6A28SUicXnD3OWZ2u5l1jx12pZnNMbPPgCuB8+MVj+RCnTohyUpJCYtWffll3E95003Qty8MHRp+KskSkTw4A/jOzO4xs4OiDkZERASgRDzf3N0nABO223Zzluc3AjfGMwbJo/r1Q5J15JHQqRO8915YLThOzODOO+HPP+Hee2HtWnjgASgR1/8yRSQRuPvZZrYXcCYwwswceBIY5e4ro41ORESSlYZWyI4aNICJE2HTJujYMSxeFUdm8PDDcM018NBDodbGH3/E9ZQikiDc/U9gDGEpkBrAScBMM7si0sBERCRpKcGS7DVqFKoL/vVXSLLmz4/r6YoVCz1Xjz8OkydD69bw7bdxPaWIFHFm1t3MxgKTgZJAS3fvAjQDrosyNhERSV5KsCRnTZuGWurLl4cka9GiXf7KnrrwwtB59vvv0KoVvPVW3E8pIkXXKcBAd2/i7ve6+28A7r4GuDDa0EREJFkpwZKdO/RQePNNWLIkJFm//BL3Ux5xBEyfDrVrQ5cuMHiwil+ISLZuBT7Z8sLMyppZKoC7T4woJhERSXJKsGTXWrWCCRNCD9bRR4dkK85SU+HDD+GEE+Cqq+Dii2H9+rifVkSKlheBrKvobYptExERiYwSLMmddu3g1Vfh++/DOlm//x73U1aoAC+/HEq5P/ZYOO3SpXE/rYgUHSXcfetXL7HnpSKMR0RERAmW5EGHDjBuHHz1FRx3HKxYEfdTFisGAwbAyJEwbRocdhh88UXcTysiRcOSLOsqYmY9AH0NIyIikVKCJXlz7LHw0kvw2WfQuTOsLJilZs46C6ZMgXXroG1bGD++QE4rIoXbJcBNZrbAzH4C+gIXRxyTiIgkOSVYknfdusHzz4dKFMcfD6tXF8hpW7YMpzzoIDjxRLj1Vs3LEklm7v69u7cGGgEHu3tbd5+7q98zs+Fm9puZzc5hv5nZYDOba2afm9mhWfadZ2bfxR7n5d/ViIhIoshVgmVm5cysWOx5w9jaIyXjG5oUaiedFMbtffghdO8e1ssqADVrhp6sjAy47TZISwvrZolIcjKz44HLgGvN7GYzuzkXvzYC6LyT/V2ABrFHL+DR2Ln2Bm4BWgEtgVvMrPLuRy8iIokotz1YU4AyZlYTeAs4h9BASTI74wwYMQImTYKTTw7j9wpA2bLwzDPw2muwdm2YGnbeefDbbwVyehEpJMxsKHAGcAVgwGlA3V39nrtPAXZWqacH8LQHHwOVzKwGcBzwtrv/7u5/AG+z80RNRESSUG4TLIst3Hgy8Ii7nwYcEr+wpMg455xQ4u+NN+C00wp0zF7XrjB7dqgyOGpUGDo4bBhs3rzr3xWRhNDW3c8F/nD324A2QMN8eN+awE9ZXi+Mbctp+w7MrJeZZZpZ5pICWNpCREQKj1wnWGbWBsgAXottKx6fkKTIufBCGDIklHE/6yzYuLHATp2SEqoMfvYZNG0a1stq1y68FpGEtzb2c42Z7QdsAGpEGM9W7j7M3dPdPb1atWpRhyMiIgUotwnW1cCNwFh3n2Nm9YFJcYtKip7LLoOBA0OFwXPPhU2bCvT0Bx8cRio+9RTMnQstWsB11xVYkUMRicarZlYJuBeYCcwDnsuH910E1M7yulZsW07bRUREtspVguXu77l7d3e/O1bsYqm7Xxnn2KSoufpquOuuMF7voosKfKyeWcjtvv46dKo98AA0ahQWK3Yv0FBEJM5ibdFEd1/u7i8R5l4d5O65KXKxK+OBc2PVBFsDK9x9MfAmcKyZVY4Vtzg2ti1uRn4xktRBqRS7rRipg1IZ+cXIeJ6u0NP92JHuybZ0P7al+7GjgrgnJXJzkJk9R1hvZBMwHdjLzB5093vzPSIp2vr2DZUnbr0VSpWCoUND5lOA9t4b/vc/OP98uOQSOOWUsGTXlVfCMcdAiVz9Vy8ihZm7bzazIUDz2Ot1QK4q7ZjZKKA9UNXMFhIqA5aMvc9QYALQFZgLrAEuiO373cz+Q2gHAW53950Vy9gjI78YSa9Xe7FmwxoA5q+YT69XewGQ0SQjXqcttHQ/dqR7si3dj23pfuyooO6JeS6+2jezWe6eZmYZwKFAP2CGuzfNt0hyKT093TMzMwv6tJIX7tC/P9x5J/TuDYMHF3iStcXGjeH0AwbA779DtWrQsyecfTYcdlhkYYlINsxshrun5+H4+4CPgJc9N41ZRHa33UodlMr8FfN32F66eGla12qdH6EVKR8v/Jh1m3bMoZP1foDuyfZ0P7al+7GjnO5J3Yp1mXf1vDy/X07tVm7nYJWMrXt1IjDe3TcAhbYxk4iZhYzm2mvh4Yfh+usjG6NXokQIY/FieOUVaN8+VBps1QoaNgxrac3d5bKkIlJIXQy8CKwzsz/NbKWZ/Rl1UPllwYoF2W7P7h8HySCn607W+wG6J9vT/diW7seOcrr2nD5vd1duB0v9jzB5+DNgipnVBRKmEZM4MIP77gtl2++/H8qUgTvuiCycUqWgR4/wWLEi1OJ49tmQYN16K7RuHXq1Tj899HKJSOHn7hWijiGe6lSsk20PVt2KdZl8/uSCDyhiOfXoJev9AN2T7el+bEv3Y0c53ZM6Fevk63lyW+RisLvXdPeusYUX5wMd8jUSSTxm8OCD8M9/hh6t//wn6ogAqFgR/vEPePddWLAA7rkH1qwJoxn32w+6dYNHHoFPPy3QivMikkdmdmR2j6jjyi8DOg0gpWTKNttSSqYwoNOAiCKKlu7HjnRPtqX7sS3djx0V1D3JbZGLioRJwFsarveA24EV+RqNJJ5ixUKhi/Xr4eaboXRpuOGGqKPaqlatMILx+uvhiy9g5MhQBPG12Gpv5cpBy5bQpk14tG4NVatGG7OIbHV9ludlgJbADKBjNOHkry0TrvtP7M+CFQuoU7EOAzoNSNrJ6bofO9I92Zbux7Z0P3ZUUPckt0UuXgJmA0/FNp0DNHP3k/M1mlxQkYsiatOmMAZv9OiwXtbVV0cdUY7cYf58mDoVPvooPGbN+ntpr4YN/0642rSBQw6B4lp2W2SP5bXIRTa/XxsY5O6n5GNYe0ztlohIYsqp3crtHKz9t2uwbjOzWfkSmSSH4sXh6adDT9Y114SerEsvjTqqbJlBamp4nHVW2LZ6NWRm/p1wTZgQFjUGqFEjdMpdfDGULRtV1CICLAQOjjoIERFJbrlNsP4ys3bu/gGAmR0O/BW/sCQhlSwZxt+deipcdlmoPHHhhVFHlSvlysFRR4UHhF6u778PvVxPPhlyxrvuConWJZdASsrO309E9pyZPcTfFW2LAWnAzMgCEhERIfdl2i8BhpjZPDObBzxMKI8rkjelSsGLL8Jxx4XiF888E3VEu8UMDjgAzj0XJk2C994LQwWvuw7q1QsFFFevjjpKkYSXSZhzNYOwHlZfdz872pBERCTZ5baK4Gfu3gxoCjR19+YkyCRiiUDp0jB2LHToAOefD88/H3VEe+zII2HiRHj/fWjaNBTNqFcvVChctSrq6EQS1hjgWXd/yt1HAh+bmfqPRUQkUrntwQLA3f909y3rX10bh3gkWZQtC+PHw+GHQ0ZGSLgSQLt28Pbb8OGH0Lw59O0bEq277oKVK6OOTiThTASyznwsC7wTUSwiIiJAHhOs7Vi+RSHJqVy5UA/9sMPgjDP+ro2eANq2hTffDAUx0tPhxhtD0Yz//hf+0uxFkfxSxt239hHHnqsHS0REIrUnCdau67uL7EqFCvD662Fc3SmnwFtvRR1RvmrdOlzetGnhef/+0KoVfPVV1JGJJITVZnbolhdm1gIVYBIRkYjtNMEys5Vm9mc2j5XAfgUUoyS6SpVCYnXggdCjB0yeHHVE+a5ly9BBN2EC/PILtGgBjz8eqhGKyG67GnjRzN43sw+A54He0YYkIiLJbqcJlrtXcPe9snlUcPfclngX2bW994Z33oH69aFbtzCJKQF16QKffRaGEP7zn9CzJ6xYEXVUIkWTu08HDgIuJVS7PdjdZ0QblYiIJLs9GSIokr+qVQul+GrWDJnItGlRRxQXNWqEDrs774SXXoK0NPj446ijEil6zOxyoJy7z3b32UB5M7ss6rhERCS5xTXBMrPOZvaNmc01s347Oe4UM3MzS49nPFIEVK8O774bkq3jjoOZiblmaLFi0K8ffPBBeN2uXag0uHlztHGJFDH/dPflW164+x/AP6MLR0REJI4JlpkVB4YAXYBGwJlm1iib4yoAVwGJ2V0heVezZkiyKlaEY46BL76IOqK4ad0aPv001Pe48UY49lhYvDjqqESKjOJmtrWibazdKRVhPCIiInHtwWoJzHX3H9x9PTAa6JHNcf8B7gbWxjEWKWrq1oVJk8J6WZ06JXTZvUqVYPRoeOwxmDoVmjULlQdFZJfeAJ43s05m1gkYBej/HhERiVQ8E6yawE9ZXi+MbdsqVl63trvvdAEkM+tlZplmlrlkyZL8j1QKp/r1Q09W8eIhyfruu6gjihszuOgiyMwMoyS7doXrroP166OOTKRQ6wu8SyhwcQnwBdsuPCwiIlLgIityYWbFgAeA63Z1rLsPc/d0d0+vVq1a/IOTwqNhw1D4YsMG6NgRfvwx6ojiqlGjUNvjssvggQdCtcFvv406KpHCyd03E4aXzyOMmugIJG53t4iIFAnxTLAWAbWzvK4V27ZFBaAxMNnM5gGtgfEqdCE7aNQolHBfvRo6dIAFC6KOKK7KloUhQ2Ds2JBPNm8OTzyhNbNEtjCzhmZ2i5l9DTwELABw9w7u/nC00YmISLKLZ4I1HWhgZvXMrBTQExi/Zae7r3D3qu6e6u6pwMdAd3fPjGNMUlQ1awZvvw3Ll8Nhh0GtWqEUX2oqjBwZdXRxceKJ8PnnoRDGRRfB6afDH39EHZVIofA1obeqm7u3c/eHgE0RxyQiIgLEMcFy941Ab+BNwpCNF9x9jpndbmbd43VeSWAtWsA118Bvv8GiRaFLZ/586NUrYZOsmjVDXnn33fDKK9C0Kbz3XtRRiUTuZGAxMMnMHosVuLBd/I6IiEiBiOscLHef4O4N3X1/dx8Q23azu4/P5tj26r2SXXryyR23rVkD/fsXfCwFpFgxuOEG+OijMHywQ4dwuRs2RB2ZSDTc/RV37wkcBEwCrgb2MbNHzezYSIMTEZGkF1mRC5HdktP8q/nzYfBgWLasYOMpQOnpYd3lf/wD/vvfsDjx999HHZVIdNx9tbs/5+4nEOb5fkqoLCgiIhIZJVhStNSpk/32UqXgqqtgv/3CZKXXX4dNiTclo3x5ePxxePHFUF0wLQ2eekoFMETc/Y9YxdlOUcciIiLJTQmWFC0DBkBKyrbbUlJg+HCYNQsuvTSsndW1a1isuH9/mDs3klDj6dRTQwGMQw+F88+Hs84K9T9EREREJFpKsKRoyciAYcNC8mQWfg4bFrY3awaDBoUCGGPGhNd33QUNGsCRR8KIEbBqVdRXkG9q1w655IABoUeradNw2erNEhEREYmOEiwpejIyYN482Lw5/MzI2HZ/6dJwyinw2mthztZ//wuLF8MFF0CNGqHm+dSpCZGJFC8ON90EH34IlSvDaaeFIhizZkUdmYiIiEhyUoIlia1mTbjxxjBh6f33QwYyejQcfjgcfHCof754cdRR7rFWrUIBjKFDYc6cMHSwV69Q0V5ERERECo4SLEkOZqHs3vDhIaF64gmoVg369Qtj7U44AcaOhfXro450txUvDhdfDN99B1dfHSraN2gA999fpC9LREREpEhRgiXJp0KFUOv8/ffhm2/g+uthxgw4+WSoVQuuvRZmz446yt1WqRI88EC4hHbtoE8faNwYXn01IUZFiuwxM+tsZt+Y2Vwz65fN/rpmNtHMPjezyWZWK8u+e8xsjpl9ZWaDzUwLHIuIyDaUYElya9gQ7rwzzNV67bVQDOPhh6FJE2jZMoy5K6Ll+Q48MFzShAmhd6t7dzjuuDCEUCRZmVlxYAjQBWgEnGlmjbY77D7gaXdvCtwO3Bn73bbA4UBToDFwGHBUAYUuIiJFhBIsEYASJUJp9zFjQhXCgQNh7dpQ9r1GjVBIY+LEUFijiOnSJZR0HzQIpk8PxRWvuELzsyRptQTmuvsP7r4eGA302O6YRsC7seeTsux3oAxQCigNlAR+jXvEIiJSpCjBEtletWphEtNnn4WM5B//CF1BRx8N9evDbbfB/PlRR5knJUuGdZi/+y7M03rkkbBm88UXh1GSIkmkJvBTltcLY9uy+gw4Ofb8JKCCmVVx948ICdfi2ONNd/8qu5OYWS8zyzSzzCVLluTrBYiISOGmBEskJ2aQng5DhoTCGM89F6pG3HYb1KsHxxwTtv31V9SR5lrVquFyvvwSzjsPnnoqFFM88UT44APN0RKJ6QMcZWafEoYALgI2mdkBwMFALUJS1tHMjsjuDdx9mLunu3t6tWrVCipuEREpBJRgieRG2bJw5pnw9tvw449w660wd24YOlijBlx2GWRmFpkM5cAD4X//C1PP/v3vkFwdcQS0aRNGSW7aFHWEInGzCKid5XWt2Lat3P1ndz/Z3ZsD/WPblhN6sz5291Xuvgp4HWhTIFGLiEiRoQRLJK/q1oWbb4bvvw/zsrp1CzXRDzssTHAaOBCKyJCgffYJHXILFoSeraVLw1JhDRuG16tXRx2hSL6bDjQws3pmVgroCYzPeoCZVTWzLe3jjcDw2PMFhJ6tEmZWktC7le0QQRERSV5KsER2V7Fi0LEjPPtsGEL46KOhp+vaa8MCx6ecEuZubdwYdaS7lJISOuG++QZeeikkXr17h3la//43/PJL1BGK5A933wj0Bt4kJEcvuPscM7vdzLrHDmsPfGNm3wL7AgNi28cA3wNfEOZpfeburxZk/CIiUviZF5EhTVukp6d7ZmZm1GGI5Gz27NCj9cwzoSerRo0w4emCC0LXUBHx4Ydw330wblzIJTt1CqMkTzoJKlaMOjpJRGY2w93To44jv6ndEhFJTDm1W+rBEslvjRvD/ffDwoXw8suhUMa994aJT+3awfDhsHJl1FHu0uGHw9ix8PXX0LcvfPttyBH33Td0zo0ZU6Tqe4iIiIgUCCVYIvFSqlTo7hk/Hn76Ce6+O0xyuvDC0Kv1j3/A++8X+sIYDRvCgAHwww/w0UehtPuHH4a5WvvuC+eeC6+/Dhs2RB2piIiISPSUYIkUhBo14IYb4KuvQnZy5pnw4otw5JGhZ+vOO8MCx1uMHAmpqWFsXmpqeB0xM2jdGh58MIT6zjtw+unw6qthjeb99gvrMk+ZUiTXYxYRERHJF5qDJRKV1avDOLvhw0NWUqwYdO4MBxwAjz8Oa9b8fWxKCgwbFsrCFzLr1sEbb8CoUaGz7q+/Qo2PM86Anj3DCEmzqKOUokBzsEREpCjJqd1SgiVSGMydCyNGhMeiRdkfU7cuzJtXgEHl3apVIcl6/vm/hw3Wrx8SrZ49w/Q0JVuSEyVYIiJSlKjIhUhhdsABcMcdMH9+zhnIggUFG9NuKF8ezjorVB789dfQOXfAAWH6WdOmIcH6z3/gu++ijlREREQkPpRgiRQmxYuHxaey4x7G3b3xBmzaVLBx7YbKlUPVwTffhJ9/hkcegapV4ZZbQuGMFi1CccXFi6OOVERERCT/KMESKWwGDAhzrrIqUwaOOy5UlujSJRS+6N8/DC0sAvbZJxTAeO+90BH3wANQokSo+5GaGvb9+GPUUYqIiIjsOSVYIoVNRkYoaFG3bhguWLduKHrxxhuhK+jFF6FJE7jrLmjQIFQifPLJMAGqCKhVC665BqZN+3ttreHDw6Wccw7MmRN1hCIiIiK7TwmWSGGUkREKWmzeHH5uqR5YujSceipMmBC6gu68E375JaypVb16kVlba4sGDWDo0NB7ddVVYV3mxo3D8mHTp0cdnYiIiEjeKcESKapq1oR+/eCbb+CDD0KZvi1razVsCP/9LyxcGHWUubLffnD//SFnvPlmmDwZWraEY48Nz4tIvigiIiKiBEukyDODww8Pwwh/+SWUeq9ZM8zRqls3zNl64YWwYFUhV6UK3HZbSLTuuQc+/xw6dAiX93//p0RLRERECj8lWCKJpFw5OO+80O0zdy7cdFOY1HTGGVCjBlxxBcycWegzlQoV4Prrw9DBIUPC1LMTToBmzcJ8rbVro45QREREJHtKsEQS1f77h0Wnfvwx1Eo/7jh47LFQHz0tDR58EJYujTrKnSpbFi67LKybNWJE2HbhhVC7NvzrXyHxEhERESlMlGCJJLrixcNkplGjwqJTQ4ZAqVJw9dVh8tOpp8Jrr8HGjVFHmqOSJUPH3GefwbvvQtu2YYpZ3bphYeNp06KOUERERCRQgiWSTCpXDl1C06eHCU69e8OUKdCtW1jgeEvRjELKLMzJGjcu9Gr17h3mZrVuDW3awOjRsGFD1FGKiIhIMotrgmVmnc3sGzOba2b9stl/iZl9YWazzOwDM2sUz3hEJIsmTcKKvwsXhvro6elw331w0EF/F83488+oo8zR/vvDwIEh/C2jHc88E+rVC71bhXz0o4iIiCSouCVYZlYcGAJ0ARoBZ2aTQD3n7k3cPQ24B3ggXvGISA5KlQoLT40fH7KVe+6BP/6Af/4zFMbYUjRj8+aoI83WXnvBlVeGjrdXX4WDDw4FFGvXDvO1Zs6MOkIRERFJJvHswWoJzHX3H9x9PTAa6JH1AHfP+vV4OaBwlzYTSXTVq4fyfXPmwEcfwdlnwyuvhHF5BxwQimYsWBB1lNkqViyMdHz7bZg9G849NwwZbNEizNl67jlYvz7qKEVERCTRxTPBqgn8lOX1wti2bZjZ5Wb2PaEH68rs3sjMeplZppllLlmyJC7BikgWZmFi0//+FwpjPPNMGHt3882Qmvp30Yy//oo60mwdckgIfdGiMIxwyRLIyAjTzP797yKz/rKIiIgUQZEXuXD3Ie6+P9AX+FcOxwxz93R3T69WrVrBBiiS7FJSQk/WxInwww8hyfr221C+r0YNuPTSUDSjEK6tValSKJb4zTfw+utw2GEwYEDIEU87Dd57r1CGLSIiIkVYPBOsRUDtLK9rxbblZDRwYhzjEZE9Va8e3HprSLTeeSeMyRsxAlq2DEUz7r8ffv016ih3UKwYdO4c5mjNnQvXXBPyxfbtQ9hDh8KqVVFHKSIiIokgngnWdKCBmdUzs1JAT2B81gPMrEGWl8cD38UxHhHJL8WKQadO8OyzYQjh0KFQvjz06QO1asGJJ4aiGYWwZnr9+nDvvWGY4BNPhDW2Lr009GrddZcSLREREdkzcUuw3H0j0Bt4E/gKeMHd55jZ7WbWPXZYbzObY2azgGuB8+IVj4jESaVKcPHF8PHHoTjG1VeH5z16hGSrT5+wvZBJSYF//CNUGfzgg9AJd+ONoZPu3nth9eqoIxQREZGiKK5zsNx9grs3dPf93X1AbNvN7j4+9vwqdz/E3dPcvYO7F75/hYlI7jVqFLKTn34KqwG3bRsWqWrcGFq1Cj1dy5eHY0eODN1GxYqFnyNHRhKyWVj2a8IEmDoVDj0Ubrgh9HQ98ACsWRNJWCIiIlJERV7kQkQSUMmS0L07jB0bSvndf3/oErr00lAYo23bsEjV/PmhysT8+dCrV2RJ1hZt2sCbb8KHH0LTpnDddSHRGjSo0BZMFBERkUJGCZaIxNc++8C118IXX8Ann8AFF4QhhOvWbXvcmjVhheBCoG3bsJ7WlCmhU+6aa2D//eGhh2Dt2qijExERkcJMCZaIFAyzUCf9kUdyPqaQLWJ8xBHw7rsweTI0aABXXhnWWx4yRImWiIiIZE8JlogUvDp1st9eujR89VXBxpILRx0VkqyJE0MRjN69Q4/WoEGaoyUiIiLbUoIlIgVvwIBQxi+rkiVDL1eTJnDVVfDHH9HElgMz6NgxDBucOBEaNgxDB+vVg3vugZUro45QRERECgMlWCJS8DIyYNgwqFs3ZC5168KTT4ZiFxddBA8/HMbkPfIIbNwYdbTb2JJoTZoE778PaWnQt28ohHjHHbBiRdQRioiISJSUYIlINDIyYN482Lw5/MzIgGrVQin3mTNDT9bll0Pz5qHLqBBq1y5UHZw2LRTG+Pe/Q654883w++9RRyc5MbPOZvaNmc01s37Z7K9rZhPN7HMzm2xmtbLsq2Nmb5nZV2b2pZmlFmjwIiJS6CnBEpHCp1mzUF3ipZdCefejj4YTT4S5c6OOLFstW8Krr4a8sFMn+M9/QqLVrx/89lvU0UlWZlYcGAJ0ARoBZ5pZo+0Ouw942t2bArcDd2bZ9zRwr7sfDLQE9BcWEZFtKMESkcLJDE4+Gb78Ev77X3jnHTjkkDAe788/o44uW82bh5zwiy+gW7cwNys1Fa64otDmhsmoJTDX3X9w9/XAaKDHdsc0At6NPZ+0ZX8sESvh7m8DuPsqd1eZExER2YYSLBEp3MqUgRtvhO++g7POCllLw4bwxBOwaVPU0WWrcWMYNSoURDzjDPjf/0LI3buHuVvuUUeY1GoCP2V5vTC2LavPgJNjz08CKphZFaAhsNzMXjazT83s3liP2A7MrJeZZZpZ5pIlS/L5EkREpDBTgiUiRUONGqEQxiefQP36oRhGy5ah0kQhdeCBIeQFC+Bf/4KPPgoFMg49FJ56ase1lqXQ6AMcZWafAkcBi4BNQAngiNj+w4D6wPnZvYG7D3P3dHdPr1atWoEELSIihYMSLBEpWg47DD78EEaODBOcjjwydBPNnx91ZDmqXh1uvz0kWo8/Dhs2wPnnh3lat9+ueVoFbBFQO8vrWrFtW7n7z+5+srs3B/rHti0n9HbNig0v3Ai8AhxaEEGLiEjRoQRLRIoeszBc8Ouv4ZZbQoWJgw4K5ftWr446uhyVLQsXXhjmaL31FrRoEcKvU+fv7RJ304EGZlbPzEoBPYHxWQ8ws6pmtqV9vBEYnuV3K5nZli6pjsCXBRCziIgUIUqwRKToKlcObr01JFonnhjK9x14YOjdKsQTnczgmGPgtdfCPK0LLghztpo2hQ4dwhJhmrYTH7Gep97Am8BXwAvuPsfMbjez7rHD2gPfmNm3wL7AgNjvbiIMD5xoZl8ABjxWwJcgIiKFnHkh/kdIdtLT0z0zMzPqMESkMPrwQ7jqKpgxA1q3hgcfDPO0ioBly0Ji9eSToZ5H8eIh2Tr9dDjpJKhaNeoI48/MZrh7etRx5De1WyIiiSmndks9WCKSOA4/PBTBGD48LF7cqhWcdx78/HPUke1SlSqhWOI338CsWaEa/bx50KtXmMN13HGhcOKyZVFHKiIiIjujBEtEEkuxYmHM3bffhpV+R48ONdIHDIC//oo6ul0yC+ssDxgQLmHmTLj++rCO1kUXhWSrc+eQQ/7+e9TRioiIyPaUYIlIYqpQAe68MyxUfOyxoU76wQfDmDGFen5WVmZh8eI77wwJVmYmXHddSLwuvBD23Rfatw/7P/0UNm+OOmIRERFRgiUiiW3//eHll2HiRNhrLzjttJCVzJoVdWR5YhaqDt51F3z/PUyfHpKt5cvhppvC2lo1asC558Jzz6lIhoiISFSUYIlIcujYMYy3e/RRmDMnZCS9ehXJRajMID09JFuzZoUpZiNGQKdOMGECZGSE3q3DDgsddx98ABs3Rh21iIhIclCCJSLJo0QJuOSSUKbvqqtCyb4GDeD++2H9+qij2201aoRaHs89B7/+Gup83HYblC4dhg8ecUQoonHmmTBuHKxbF3XEIiIiiUsJlogkn8qVYeDAsLJvu3bQpw80bhwWLC4i87NyUrx46Ln6979Dz9WyZWHa2WmnwTvvhOXC9t031AF5803YsCHqiEVERBKLEiwRSV4HHRRW+50wIVQf7N491EOfMyfqyPJNpUpwyinw+ONhKOEbb4R1tV5+OVQj3G8/uPRSeO892LQp6mhFRESKPiVYIiJduoTerEGDQvWIZs3giisSrg56yZIhf3zyyTCU8JVX4Oij4emnQ92POnXgmmtg2rQi35EnIiISGSVYIiIQso+rrgrzs3r1gkcegQMOgIcfTsgKEWXKQI8eMGpUqPMxejS0bBkuu3VrqF8/jJycOlXl30VERPJCCZaISFZVq4YsY9assAjVFVeEHq233oo6srgpVw7OOAPGjg3J1ogR0KgRDB4Mhx8OtWtD797w7rsJmWuKiIjkKyVYIiLZadIkVIUYOxbWrg1j6044Iazym8AqVgwVCV97LaylNXJk6NEaPjyUga9ePSxyPGGCqhGKiIhkRwmWiEhOzELZvS+/hLvvhsmTQ7XBPn1gxYqoo4u7ihXhrLPgpZdg6dLws3PnUJXw+ONhn33CmlsvvQSrV0cdrYiISOGgBEtEZFdKl4Ybbgjzs845Bx54IKyf9dhjSVN6LyUFTj4Znn02DCOcMCGUfn/rLTj1VLjjjqgjFBERKRyUYImI5Fb16vDEE6HSYMOGoRhGenqocZ5ESpcOhRcffxwWL4ZJk+Cii6KOSkREpHBQgiUiklctWsD774fSe8uWhRrnp50G8+ZFHVmBK1EiXP7++0cdiYiISOGgBEtEZHeYhdJ7X38Nt90WqkIcdBD07w+rVkUdnYiIiEQkrgmWmXU2s2/MbK6Z9ctm/7Vm9qWZfW5mE82sbjzjERHJdykpcPPNobrgqafCf/8bhg8+/XSYsJSaCsWKhZ8jR0YdrYiIiMRZ3BIsMysODAG6AI2AM82s0XaHfQqku3tTYAxwT7ziERGJq1q1QkI1dWp4ft554TF/PriHn716KckSERFJcPHswWoJzHX3H9x9PTAa6JH1AHef5O5rYi8/BmrFMR4Rkfhr0wY+/hiqVIHNm7fdt2ZNGEIoIiIiCSueCVZN4KcsrxfGtuXkQuD17HaYWS8zyzSzzCVLluRjiCIicVCsGPz+e/b7Fiwo2FhERESkQBWKIhdmdjaQDtyb3X53H+bu6e6eXq1atYINTkRkd9Spk7ftIiIikhDimWAtAmpneV0rtm0bZnY00B/o7u7r4hiPiEjBGTAgFMDIKiUlbBcREZGEFc8EazrQwMzqmVkpoCcwPusBZtYc+B8hufotjrGIiBSsjAwYNgzq1g0l3evWDa8zMqKOTEREROKoRLze2N03mllv4E2gODDc3eeY2e1ApruPJwwJLA+8aGYAC9y9e7xiEhEpUBkZSqhERESSTNwSLAB3nwBM2G7bzVmeHx3P84uIiIiIiBSkQlHkQkREREREJBEowRIREREREcknSrBERERERETyiRIsERERERGRfGLuHnUMeWJmS4D5e/g2VYGl+RBOYaZrTAy6xsSga8yduu6ecKvJq92KC92PHemebEv3Y1u6HzuKW7tV5BKs/GBmme6eHnUc8aRrTAy6xsSga5Q9pfu7Ld2PHemebEv3Y1u6HzuK5z3REEEREREREZF8ogRLREREREQknyRrgjUs6gAKgK4xMegaE4OuUfaU7u+2dD92pHuyLd2Pbel+7Chu9yQp52CJiIiIiIjEQ7L2YImIiIiIiOQ7JVgiIiIiIiL5JOkSLDPrbGbfmNlcM+sXdTzxYGbzzOwLM5tlZplRx5MfzGy4mf1mZrOzbNvbzN42s+9iPytHGeOeyuEabzWzRbG/5Swz6xpljHvCzGqb2SQz+9LM5pjZVbHtCfN33Mk1JtLfsYyZfWJmn8Wu8bbY9npmNi322fq8mZWKOtZEkAxtVl4lYhuXF8nQHuZVorefeZUM7W1eRNE2J9UcLDMrDnwLHAMsBKYDZ7r7l5EGls/MbB6Q7u4Js6CcmR0JrAKedvfGsW33AL+7+12xf3hUdve+Uca5J3K4xluBVe5+X5Sx5QczqwHUcPeZZlYBmAGcCJxPgvwdd3KNp5M4f0cDyrn7KjMrCXwAXAVcC7zs7qPNbCjwmbs/GmWsRV2ytFl5lYhtXF4kQ3uYV4nefuZVMrS3eRFF25xsPVgtgbnu/oO7rwdGAz0ijklywd2nAL9vt7kH8FTs+VOE/1mKrByuMWG4+2J3nxl7vhL4CqhJAv0dd3KNCcODVbGXJWMPBzoCY2Lbi/TfsRBRmyU7SIb2MK8Svf3Mq2Rob/MiirY52RKsmsBPWV4vJMH+8RPjwFtmNsPMekUdTBzt6+6LY89/AfaNMpg46m1mn8eGQCREd76ZpQLNgWkk6N9xu2uEBPo7mllxM5sF/Aa8DXwPLHf3jbFDEvWztaAlS5uVV8nSxuVFQn6O5oOE+dzdXcnQ3uZFQbXNyZZgJYt27n4o0AW4PNZ1ntA8jHVNxPGujwL7A2nAYuD+SKPJB2ZWHngJuNrd/8y6L1H+jtlcY0L9Hd19k7unAbUIvSwHRRuRJJmka+PyIlE+R/NBQn3u7o5kaG/zoiDb5mRLsBYBtbO8rhXbllDcfVHs52/AWMI/gBLRr7FxtVvG1/4WcTz5zt1/jf1jdjPwGEX8bxmbs/MSMNLdX45tTqi/Y3bXmGh/xy3cfTkwCWgDVDKzErFdCfnZGoGkaLPyKonauLxIqM/R/JCon7u5lQztbV4UdNucbAnWdKBBrNpVKaAnMD7imPKVmZWLTeDDzMoBxwKzd/5bRdZ44LzY8/OAcRHGEhdbPghjTqII/y1jxRGeAL5y9wey7EqYv2NO15hgf8dqZlYp9rwsoQDDV4RE69TYYUX671iIJHyblVdJ1sblRcJ8juaXRPrczatkaG/zIoq2OamqCALESjAOAooDw919QLQR5S8zq0/4Rg+gBPBcIlyjmY0C2gNVgV+BW4BXgBeAOsB84HR3L7KTXHO4xvaErmsH5gEXZxk/XaSYWTvgfeALYHNs802EcdAJ8XfcyTWeSeL8HZsSJkcXJ3xJ94K73x777BkN7A18Cpzt7uuiizQxJHqblVeJ2sblRTK0h3mV6O1nXiVDe5sXUbTNSZdgiYiIiIiIxEuyDREUERERERGJGyVYIiIiIiIi+UQJloiIiIiISD5RgiUiIiIiIpJPlGCJiIiIiIjkEyVYIgXAzDaZ2awsj375+N6pZpY063uIiEj8qd0S2X0log5AJEn85e5pUQchIiKSS2q3RHaTerBEImRm88zsHjP7wsw+MbMDYttTzexdM/vczCaaWZ3Y9n3NbKyZfRZ7tI29VXEze8zM5pjZW2ZWNrKLEhGRhKV2S2TXlGCJFIyy2w21OCPLvhXu3gR4GBgU2/YQ8JS7NwVGAoNj2wcD77l7M+BQYE5sewNgiLsfAiwHTonr1YiISKJTuyWym8zdo45BJOGZ2Sp3L5/N9nlAR3f/wcxKAr+4exUzWwrUcPcNse2L3b2qmS0Barn7uizvkQq87e4NYq/7AiXd/Y4CuDQREUlAardEdp96sESi5zk8z4t1WZ5vQvMrRUQkftRuieyEEiyR6J2R5edHsedTgZ6x5xnA+7HnE4FLAcysuJlVLKggRUREYtRuieyEvi0QKRhlzWxWltdvuPuWkreVzexzwrd5Z8a2XQE8aWbXA0uAC2LbrwKGmdmFhG/8LgUWxzt4ERFJOmq3RHaT5mCJRCg2lj3d3ZdGHYuIiMiuqN0S2TUNERQREREREckn6sESERERERHJJ+rBEhERERERySdKsERERERERPKJEiwREREREZF8ogRLREREREQknyjBEhERERERySf/D9kCpsZW/RHvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Evaluation:\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Metrics tracking class\n",
    "class MetricsTracker:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.test_accuracies = []\n",
    "        self.test_epochs = []  # To track epochs where test metrics are recorded\n",
    "    \n",
    "    def update(self, epoch, train_loss, test_loss=None, test_accuracy=None):\n",
    "        self.train_losses.append(train_loss)\n",
    "        if test_loss is not None:\n",
    "            self.test_losses.append(test_loss)\n",
    "            self.test_accuracies.append(test_accuracy)\n",
    "            self.test_epochs.append(epoch)\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        # Training and Test Loss plot\n",
    "        plt.subplot(1, 2, 1)\n",
    "        train_epochs = range(1, len(self.train_losses) + 1)\n",
    "        plt.plot(train_epochs, self.train_losses, 'b-', label='Training Loss')\n",
    "        \n",
    "        if self.test_losses:\n",
    "            plt.plot(self.test_epochs, self.test_losses, 'r-', marker='o', label='Test Loss')\n",
    "        \n",
    "        plt.title('Training and Test Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Test Accuracy plot\n",
    "        if self.test_accuracies:\n",
    "            plt.subplot(1, 2, 2)\n",
    "            plt.plot(self.test_epochs, self.test_accuracies, 'g-', marker='o', label='Test Accuracy')\n",
    "            plt.title('Test Accuracy')\n",
    "            plt.xlabel('Epoch')\n",
    "            plt.ylabel('Accuracy')\n",
    "            plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Helper function for GraphSAGE\n",
    "def scatter_mean(src, index, dim=-1, dim_size=None):\n",
    "    if dim_size is None:\n",
    "        dim_size = index.max().item() + 1\n",
    "    \n",
    "    out = torch.zeros((dim_size, src.size(-1)), device=src.device)\n",
    "    count = torch.zeros(dim_size, device=src.device)\n",
    "    \n",
    "    index_expanded = index.unsqueeze(-1).expand(-1, src.size(-1))\n",
    "    out.scatter_add_(0, index_expanded, src)\n",
    "    count.scatter_add_(0, index, torch.ones_like(index, dtype=torch.float))\n",
    "    \n",
    "    count[count == 0] = 1\n",
    "    count = count.unsqueeze(-1)\n",
    "    \n",
    "    return out / count\n",
    "\n",
    "# GraphSAGE Layer implementation\n",
    "class GraphSAGELayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True):\n",
    "        super(GraphSAGELayer, self).__init__()\n",
    "        self.normalize = normalize\n",
    "        self.weight = nn.Linear(in_channels * 2, out_channels, bias=True)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight.weight)\n",
    "        if self.weight.bias is not None:\n",
    "            nn.init.zeros_(self.weight.bias)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        row, col = edge_index\n",
    "        neighbor_features = x[col]\n",
    "        neighbor_mean = scatter_mean(neighbor_features, row, dim=0, dim_size=x.size(0))\n",
    "        \n",
    "        out = torch.cat([x, neighbor_mean], dim=1)\n",
    "        out = self.weight(out)\n",
    "        \n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2, dim=1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# Generator with GraphSAGE layers\n",
    "class GraphSAGEGenerator(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, output_size, num_layers=2):\n",
    "        super(GraphSAGEGenerator, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.fc_z = nn.Linear(latent_size, hidden_size)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_channels = hidden_size if i == 0 else hidden_size\n",
    "            self.conv_layers.append(GraphSAGELayer(in_channels, hidden_size))\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        x = self.fc_z(z)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.conv_layers[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "# Discriminator with GraphSAGE layers\n",
    "class GraphSAGEDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2):\n",
    "        super(GraphSAGEDiscriminator, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        first_layer = GraphSAGELayer(input_size, hidden_size)\n",
    "        self.conv_layers.append(first_layer)\n",
    "        \n",
    "        for i in range(num_layers - 1):\n",
    "            self.conv_layers.append(GraphSAGELayer(hidden_size, hidden_size))\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.conv_layers[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            \n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "# Classifier for final prediction\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, 2)  # binary classification\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Data preprocessing functions\n",
    "def df_label_encoder(df, columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df_label_encoder(df, ['merchant', 'category', 'city', 'state', 'job'])\n",
    "    df['amt'] = (df['amt'] - df['amt'].min()) / (df['amt'].max() - df['amt'].min())\n",
    "    df['node_from'] = df['cc_num'].astype(str)\n",
    "    df['node_to'] = df['merchant'].astype(str)\n",
    "    df = df.sort_values(by=['node_from'])\n",
    "    node_list = pd.concat([df['node_from'], df['node_to']]).unique()\n",
    "    return df, node_list\n",
    "\n",
    "def create_graph_data(df, node_list):\n",
    "    node_map = {node: idx for idx, node in enumerate(node_list)}\n",
    "    edge_index = np.array([[node_map[from_node], node_map[to_node]] \n",
    "                          for from_node, to_node in zip(df['node_from'], df['node_to'])], \n",
    "                         dtype=np.int64).T\n",
    "    \n",
    "    node_features = torch.tensor(df[['amt', 'category', 'city', 'state']].values, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "    labels = torch.tensor(df['is_fraud'].values, dtype=torch.long)\n",
    "    \n",
    "    return node_features, edge_index, labels\n",
    "\n",
    "# WGAN training function\n",
    "def train_wgan_graphsage(generator, discriminator, node_features, edge_index, labels, \n",
    "                        num_epochs=16, batch_size=32, critic_iterations=5):\n",
    "    \n",
    "    device = node_features.device  # Get the device from input tensors\n",
    "    \n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "    \n",
    "    real_data = node_features[labels == 1]\n",
    "    latent_size = generator.fc_z.in_features  # Get latent size from generator's first layer\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train Discriminator\n",
    "        for _ in range(critic_iterations):\n",
    "            optimizer_d.zero_grad()\n",
    "            \n",
    "            d_real = discriminator(real_data, edge_index)\n",
    "            \n",
    "            # Generate noise on the same device as other tensors\n",
    "            z = torch.randn(real_data.size(0), latent_size, device=device)\n",
    "            fake_data = generator(z, edge_index)\n",
    "            d_fake = discriminator(fake_data.detach(), edge_index)\n",
    "            \n",
    "            loss_d = -torch.mean(d_real) + torch.mean(d_fake)\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            # Clip discriminator weights\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_g.zero_grad()\n",
    "        z = torch.randn(real_data.size(0), latent_size, device=device)  # Generate noise on correct device\n",
    "        fake_data = generator(z, edge_index)\n",
    "        loss_g = -torch.mean(discriminator(fake_data, edge_index))\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        if epoch % 1 == 0:\n",
    "            print(f'Epoch [{epoch}/{num_epochs}], Loss D: {loss_d.item():.4f}, Loss G: {loss_g.item():.4f}')\n",
    "    \n",
    "    return generator, discriminator\n",
    "\n",
    "def generate_synthetic_samples(generator, num_samples, edge_index, device):\n",
    "    latent_size = generator.fc_z.in_features\n",
    "    z = torch.randn(num_samples, latent_size, device=device)\n",
    "    with torch.no_grad():\n",
    "        generated_samples = generator(z, edge_index)\n",
    "    return generated_samples\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Device configuration\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    df = pd.read_csv('creditcard/fraudTrain.csv')\n",
    "    df, node_list = preprocess(df)\n",
    "    node_features, edge_index, labels = create_graph_data(df, node_list)\n",
    "    \n",
    "    # Move data to device\n",
    "    node_features = node_features.to(device)\n",
    "    edge_index = edge_index.to(device)\n",
    "    labels = labels.to(device)\n",
    "    \n",
    "    # Model parameters\n",
    "    input_size = node_features.shape[1]\n",
    "    hidden_size = 128\n",
    "    latent_size = 64\n",
    "    num_layers = 2\n",
    "    \n",
    "    # Initialize models\n",
    "    print(\"Initializing models...\")\n",
    "    generator = GraphSAGEGenerator(latent_size, hidden_size, input_size, num_layers).to(device)\n",
    "    discriminator = GraphSAGEDiscriminator(input_size, hidden_size, num_layers).to(device)\n",
    "    \n",
    "    # Train WGAN-GP\n",
    "    print(\"Training WGAN-GP...\")\n",
    "    generator, discriminator = train_wgan_graphsage(\n",
    "        generator, discriminator, node_features, edge_index, labels\n",
    "    )\n",
    "    \n",
    "    # Generate synthetic samples\n",
    "    print(\"Generating synthetic samples...\")\n",
    "    num_samples = torch.sum(labels == 0) - torch.sum(labels == 1)\n",
    "    generated_samples = generate_synthetic_samples(generator, num_samples, edge_index, device)\n",
    "    \n",
    "    # Combine real and generated data\n",
    "    augmented_features = torch.cat([node_features, generated_samples], dim=0)\n",
    "    augmented_labels = torch.cat([\n",
    "        labels, \n",
    "        torch.ones(num_samples, dtype=torch.long, device=device)\n",
    "    ])\n",
    "    \n",
    "    # Split data for classifier training\n",
    "    x_train, x_test, y_train, y_test = train_test_split(\n",
    "        augmented_features.cpu().numpy(),\n",
    "        augmented_labels.cpu().numpy(), \n",
    "        test_size=0.2, \n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    # Convert split data to tensors and move to device\n",
    "    x_train = torch.tensor(x_train, dtype=torch.float).to(device)\n",
    "    x_test = torch.tensor(x_test, dtype=torch.float).to(device)\n",
    "    y_train = torch.tensor(y_train, dtype=torch.long).to(device)\n",
    "    y_test = torch.tensor(y_test, dtype=torch.long).to(device)\n",
    "    \n",
    "    # Initialize classifier and training components\n",
    "    print(\"Training classifier...\")\n",
    "    classifier = Classifier(input_size, hidden_size).to(device)\n",
    "    optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    metrics_tracker = MetricsTracker()\n",
    "    \n",
    "    # Training loop for classifier\n",
    "    num_epochs = 30\n",
    "    for epoch in range(num_epochs):\n",
    "        classifier.train()\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = classifier(x_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Evaluation phase\n",
    "        if epoch % 5 == 0:\n",
    "            classifier.eval()\n",
    "            with torch.no_grad():\n",
    "                test_outputs = classifier(x_test)\n",
    "                test_loss = criterion(test_outputs, y_test)\n",
    "                accuracy = accuracy_score(\n",
    "                    y_test.cpu().numpy(),\n",
    "                    test_outputs.argmax(dim=1).cpu().numpy()\n",
    "                )\n",
    "                metrics_tracker.update(\n",
    "                    epoch=epoch,\n",
    "                    train_loss=loss.item(),\n",
    "                    test_loss=test_loss.item(),\n",
    "                    test_accuracy=accuracy\n",
    "                )\n",
    "                print(f'Epoch {epoch}, Loss: {loss.item():.4f}, Test Acc: {accuracy:.4f}')\n",
    "        else:\n",
    "            metrics_tracker.update(epoch=epoch, train_loss=loss.item())\n",
    "    \n",
    "    # Plot training metrics\n",
    "    metrics_tracker.plot_metrics()\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\nFinal Evaluation:\")\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        final_outputs = classifier(x_test)\n",
    "        y_pred = final_outputs.argmax(dim=1)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        final_accuracy = accuracy_score(y_test.cpu().numpy(), y_pred.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, roc_curve, accuracy_score, confusion_matrix,\n",
    "    precision_score, recall_score, matthews_corrcoef, r2_score,\n",
    "    f1_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Enhanced Metrics tracking class\n",
    "class MetricsTracker:\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.test_losses = []\n",
    "        self.test_accuracies = []\n",
    "        self.test_precisions = []\n",
    "        self.test_recalls = []\n",
    "        self.test_f1s = []\n",
    "        self.test_mccs = []\n",
    "        self.test_r2s = []\n",
    "        self.test_roc_aucs = []\n",
    "        self.test_epochs = []\n",
    "    \n",
    "    def update(self, epoch, train_loss, test_loss=None, metrics=None):\n",
    "        self.train_losses.append(train_loss)\n",
    "        if test_loss is not None and metrics is not None:\n",
    "            self.test_losses.append(test_loss)\n",
    "            self.test_accuracies.append(metrics['accuracy'])\n",
    "            self.test_precisions.append(metrics['precision'])\n",
    "            self.test_recalls.append(metrics['recall'])\n",
    "            self.test_f1s.append(metrics['f1'])\n",
    "            self.test_mccs.append(metrics['mcc'])\n",
    "            self.test_r2s.append(metrics['r2'])\n",
    "            self.test_roc_aucs.append(metrics['roc_auc'])\n",
    "            self.test_epochs.append(epoch)\n",
    "    \n",
    "    def plot_metrics(self):\n",
    "        plt.figure(figsize=(20, 12))\n",
    "        \n",
    "        # Training and Test Loss plot\n",
    "        plt.subplot(2, 3, 1)\n",
    "        train_epochs = range(1, len(self.train_losses) + 1)\n",
    "        plt.plot(train_epochs, self.train_losses, 'b-', label='Training Loss')\n",
    "        if self.test_losses:\n",
    "            plt.plot(self.test_epochs, self.test_losses, 'r-', marker='o', label='Test Loss')\n",
    "        plt.title('Training and Test Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        \n",
    "        # Accuracy, Precision, Recall plot\n",
    "        plt.subplot(2, 3, 2)\n",
    "        if self.test_accuracies:\n",
    "            plt.plot(self.test_epochs, self.test_accuracies, 'g-', marker='o', label='Accuracy')\n",
    "            plt.plot(self.test_epochs, self.test_precisions, 'b-', marker='o', label='Precision')\n",
    "            plt.plot(self.test_epochs, self.test_recalls, 'r-', marker='o', label='Recall')\n",
    "            plt.plot(self.test_epochs, self.test_f1s, 'y-', marker='o', label='F1')\n",
    "        plt.title('Classification Metrics')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        \n",
    "        # MCC and R2 plot\n",
    "        plt.subplot(2, 3, 3)\n",
    "        if self.test_mccs:\n",
    "            plt.plot(self.test_epochs, self.test_mccs, 'p-', marker='o', label='MCC')\n",
    "            plt.plot(self.test_epochs, self.test_r2s, 'y-', marker='o', label='R2')\n",
    "        plt.title('MCC and R2 Scores')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        \n",
    "        # ROC AUC plot\n",
    "        plt.subplot(2, 3, 4)\n",
    "        if self.test_roc_aucs:\n",
    "            plt.plot(self.test_epochs, self.test_roc_aucs, 'm-', marker='o', label='ROC AUC')\n",
    "        plt.title('ROC AUC Score')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Score')\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, y_pred_proba=None):\n",
    "    \"\"\"\n",
    "    Calculate comprehensive metrics for model evaluation\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        'accuracy': accuracy_score(y_true, y_pred),\n",
    "        'precision': precision_score(y_true, y_pred),\n",
    "        'recall': recall_score(y_true, y_pred),\n",
    "        'f1': f1_score(y_true, y_pred),\n",
    "        'mcc': matthews_corrcoef(y_true, y_pred),\n",
    "        'r2': r2_score(y_true, y_pred)\n",
    "    }\n",
    "    \n",
    "    # Calculate ROC AUC if probabilities are provided\n",
    "    if y_pred_proba is not None:\n",
    "        metrics['roc_auc'] = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "    else:\n",
    "        metrics['roc_auc'] = 0.0\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "def plot_roc_curve(y_true, y_pred_proba):\n",
    "    \"\"\"\n",
    "    Plot ROC curve\n",
    "    \"\"\"\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred_proba[:, 1])\n",
    "    roc_auc = roc_auc_score(y_true, y_pred_proba[:, 1])\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')\n",
    "    plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes=['Non-Fraud', 'Fraud']):\n",
    "    \"\"\"\n",
    "    Plot confusion matrix with percentages and counts\n",
    "    \"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Calculate percentages\n",
    "    cm_percent = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "    \n",
    "    # Create annotation text with both count and percentage\n",
    "    annot = np.empty_like(cm, dtype=str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            annot[i, j] = f'{cm[i, j]}\\n({cm_percent[i, j]:.1f}%)'\n",
    "    \n",
    "    # Plot heatmap\n",
    "    sns.heatmap(cm, annot=annot, fmt='', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
    "    plt.title('Confusion Matrix\\nCount and (Percentage)')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.show()\n",
    "\n",
    "# Model architectures remain the same as before\n",
    "class GraphSAGELayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, normalize=True):\n",
    "        super(GraphSAGELayer, self).__init__()\n",
    "        self.normalize = normalize\n",
    "        self.weight = nn.Linear(in_channels * 2, out_channels, bias=True)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weight.weight)\n",
    "        if self.weight.bias is not None:\n",
    "            nn.init.zeros_(self.weight.bias)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        row, col = edge_index\n",
    "        neighbor_features = x[col]\n",
    "        \n",
    "        # Calculate mean of neighbor features\n",
    "        neighbor_mean = scatter_mean(neighbor_features, row, dim=0, dim_size=x.size(0))\n",
    "        \n",
    "        # Concatenate node's own features with neighbor features\n",
    "        out = torch.cat([x, neighbor_mean], dim=1)\n",
    "        out = self.weight(out)\n",
    "        \n",
    "        if self.normalize:\n",
    "            out = F.normalize(out, p=2, dim=1)\n",
    "        \n",
    "        return out\n",
    "\n",
    "def scatter_mean(src, index, dim=-1, dim_size=None):\n",
    "    if dim_size is None:\n",
    "        dim_size = index.max().item() + 1\n",
    "    \n",
    "    out = torch.zeros((dim_size, src.size(-1)), device=src.device)\n",
    "    count = torch.zeros(dim_size, device=src.device)\n",
    "    \n",
    "    index_expanded = index.unsqueeze(-1).expand(-1, src.size(-1))\n",
    "    out.scatter_add_(0, index_expanded, src)\n",
    "    count.scatter_add_(0, index, torch.ones_like(index, dtype=torch.float))\n",
    "    \n",
    "    count[count == 0] = 1\n",
    "    count = count.unsqueeze(-1)\n",
    "    \n",
    "    return out / count\n",
    "\n",
    "class GraphSAGEGenerator(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, output_size, num_layers=2):\n",
    "        super(GraphSAGEGenerator, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.fc_z = nn.Linear(latent_size, hidden_size)\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            in_channels = hidden_size if i == 0 else hidden_size\n",
    "            self.conv_layers.append(GraphSAGELayer(in_channels, hidden_size))\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        x = self.fc_z(z)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        for i in range(self.num_layers):\n",
    "            x = self.conv_layers[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "class GraphSAGEDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers=2):\n",
    "        super(GraphSAGEDiscriminator, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        \n",
    "        self.conv_layers = nn.ModuleList()\n",
    "        first_layer = GraphSAGELayer(input_size, hidden_size)\n",
    "        self.conv_layers.append(first_layer)\n",
    "        \n",
    "        for i in range(num_layers - 1):\n",
    "            self.conv_layers.append(GraphSAGELayer(hidden_size, hidden_size))\n",
    "        \n",
    "        self.fc_out = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for i in range(self.num_layers):\n",
    "            x = self.conv_layers[i](x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            \n",
    "        x = self.fc_out(x)\n",
    "        return x\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.fc3 = nn.Linear(hidden_size // 2, 2)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Data preprocessing functions\n",
    "def df_label_encoder(df, columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df_label_encoder(df, ['merchant', 'category', 'city', 'state', 'job'])\n",
    "    df['amt'] = (df['amt'] - df['amt'].min()) / (df['amt'].max() - df['amt'].min())\n",
    "    df['node_from'] = df['cc_num'].astype(str)\n",
    "    df['node_to'] = df['merchant'].astype(str)\n",
    "    df = df.sort_values(by=['node_from'])\n",
    "    node_list = pd.concat([df['node_from'], df['node_to']]).unique()\n",
    "    return df, node_list\n",
    "\n",
    "def create_graph_data(df, node_list):\n",
    "    node_map = {node: idx for idx, node in enumerate(node_list)}\n",
    "    edge_index = np.array([[node_map[from_node], node_map[to_node]] \n",
    "                          for from_node, to_node in zip(df['node_from'], df['node_to'])], \n",
    "                         dtype=np.int64).T\n",
    "    \n",
    "    node_features = torch.tensor(df[['amt', 'category', 'city', 'state']].values, dtype=torch.float)\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "    labels = torch.tensor(df['is_fraud'].values, dtype=torch.long)\n",
    "    \n",
    "    return node_features, edge_index, labels\n",
    "\n",
    "def train_wgan_graphsage(generator, discriminator, node_features, edge_index, labels, \n",
    "                        num_epochs=16, batch_size=32, critic_iterations=5):\n",
    "    device = node_features.device\n",
    "    \n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "    \n",
    "    real_data = node_features[labels == 1]\n",
    "    latent_size = generator.fc_z.in_features\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train Discriminator\n",
    "        for _ in range(critic_iterations):\n",
    "            optimizer_d.zero_grad()\n",
    "            \n",
    "            d_real = discriminator(real_data, edge_index)\n",
    "            z = torch.randn(real_data.size(0), latent_size, device=device)\n",
    "            fake_data = generator(z, edge_index)\n",
    "            d_fake = discriminator(fake_data.detach(), edge_index)\n",
    "            \n",
    "            loss_d = -torch.mean(d_real) + torch.mean(d_fake)\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            # Clip discriminator weights\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_g.zero_grad()\n",
    "        z = torch.randn(real_data.size(0), latent_size, device=device)\n",
    "        fake_data = generator(z, edge_index)\n",
    "        loss_g = -torch.mean(discriminator(fake_data, edge_index))\n",
    "        loss_g.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_wgan_graphsage(generator, discriminator, node_features, edge_index, labels, \n",
    "                        num_epochs=16, batch_size=32, critic_iterations=5, tracker=None):\n",
    "    device = node_features.device\n",
    "    \n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001, betas=(0.5, 0.9))\n",
    "    \n",
    "    real_data = node_features[labels == 1]\n",
    "    latent_size = generator.fc_z.in_features\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training loop for Discriminator\n",
    "        for _ in range(critic_iterations):\n",
    "            optimizer_d.zero_grad()\n",
    "            \n",
    "            # Real data predictions\n",
    "            d_real = discriminator(real_data, edge_index)\n",
    "            z = torch.randn(real_data.size(0), latent_size, device=device)\n",
    "            \n",
    "            # Generate fake data\n",
    "            fake_data = generator(z, edge_index)\n",
    "            d_fake = discriminator(fake_data.detach(), edge_index)\n",
    "            \n",
    "            # Discriminator loss\n",
    "            loss_d = -torch.mean(d_real) + torch.mean(d_fake)\n",
    "            loss_d.backward()\n",
    "            optimizer_d.step()\n",
    "            \n",
    "            # Clip discriminator weights\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-0.01, 0.01)\n",
    "        \n",
    "        # Training loop for Generator\n",
    "        optimizer_g.zero_grad()\n",
    "        z = torch.randn(real_data.size(0), latent_size, device=device)\n",
    "        fake_data = generator(z, edge_index)\n",
    "        loss_g = -torch.mean(discriminator(fake_data, edge_index))\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        # Logging losses\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss D: {loss_d.item():.4f}, Loss G: {loss_g.item():.4f}\")\n",
    "        \n",
    "        if tracker:\n",
    "            # Optionally track metrics if a tracker is provided\n",
    "            tracker.update(epoch, train_loss=loss_d.item(), test_loss=loss_g.item())\n",
    "\n",
    "    # Optionally, plot the metrics after training\n",
    "    if tracker:\n",
    "        tracker.plot_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_final_metrics(generator, classifier, node_features, edge_index, labels, tracker=None):\n",
    "    device = node_features.device\n",
    "    \n",
    "    # Split data into real and generated samples\n",
    "    real_data = node_features[labels == 1]\n",
    "    latent_size = generator.fc_z.in_features\n",
    "    z = torch.randn(real_data.size(0), latent_size, device=device)\n",
    "    \n",
    "    # Generate synthetic fraud samples\n",
    "    generated_data = generator(z, edge_index).detach()\n",
    "    \n",
    "    # Combine real and generated data for evaluation\n",
    "    combined_data = torch.cat([real_data, generated_data], dim=0)\n",
    "    combined_labels = torch.cat([torch.ones(real_data.size(0), dtype=torch.long, device=device),\n",
    "                                 torch.zeros(generated_data.size(0), dtype=torch.long, device=device)])\n",
    "    \n",
    "    # Make predictions using the classifier\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = classifier(combined_data)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        probs = F.softmax(outputs, dim=1).cpu().numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = calculate_metrics(combined_labels.cpu(), preds.cpu(), probs)\n",
    "    \n",
    "    # Print metrics\n",
    "    print(\"\\nFinal Evaluation Metrics:\")\n",
    "    print(f\"Accuracy: {metrics['accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['f1']:.4f}\")\n",
    "    print(f\"MCC: {metrics['mcc']:.4f}\")\n",
    "    print(f\"R2 Score: {metrics['r2']:.4f}\")\n",
    "    print(f\"ROC AUC: {metrics['roc_auc']:.4f}\")\n",
    "    \n",
    "    # Optionally update tracker with final metrics\n",
    "    if tracker:\n",
    "        tracker.update(epoch='Final', train_loss=0, metrics=metrics)\n",
    "        tracker.plot_metrics()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fa542bb2f06e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Assume 'classifier' is a trained instance of the Classifier class\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mevaluate_final_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
     ]
    }
   ],
   "source": [
    "# Assume 'classifier' is a trained instance of the Classifier class\n",
    "evaluate_final_metrics(generator, classifier, node_features, edge_index, labels, tracker=tracker)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
