{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girishkk/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing and Label Encoding\n",
    "def df_label_encoder(df, columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset and extract features for node creation\n",
    "def preprocess(df):\n",
    "    df = df_label_encoder(df, ['merchant', 'category', 'city', 'state', 'job'])\n",
    "    df['amt'] = (df['amt'] - df['amt'].min()) / (df['amt'].max() - df['amt'].min())\n",
    "    df['node_from'] = df['cc_num'].astype(str)\n",
    "    df['node_to'] = df['merchant'].astype(str)\n",
    "    df = df.sort_values(by=['node_from'])\n",
    "    node_list = pd.concat([df['node_from'], df['node_to']]).unique()\n",
    "    return df, node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_data(df, node_list):\n",
    "    # Create a mapping of node names to indices\n",
    "    node_map = {node: idx for idx, node in enumerate(node_list)}\n",
    "    \n",
    "    # Convert edges to indices\n",
    "    edge_index = np.array([\n",
    "        [node_map[from_node], node_map[to_node]] for from_node, to_node in zip(df['node_from'], df['node_to'])\n",
    "    ], dtype=np.int64).T  # Transpose to get the shape [2, num_edges]\n",
    "\n",
    "    # Node features (converted to numpy array or tensor)\n",
    "    node_features = torch.tensor(df[['amt', 'category', 'city', 'state']].values, dtype=torch.float)\n",
    "\n",
    "    # Labels (0 for non-fraud, 1 for fraud)\n",
    "    labels = torch.tensor(df['is_fraud'].values, dtype=torch.long)\n",
    "\n",
    "    return node_features, edge_index, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and preprocess\n",
    "df = pd.read_csv('creditcard/fraudTrain.csv')  # Update with your .csv file path\n",
    "df, node_list = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph dataset\n",
    "node_features, edge_index, labels = create_graph_data(df, node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "def plot_class_distribution(y_data, title):\n",
    "    classes, counts = torch.unique(y_data, return_counts=True)\n",
    "    plt.bar(classes.numpy(), counts.numpy())\n",
    "    plt.title(title)\n",
    "    plt.xticks([0, 1], ['Non-Fraud', 'Fraud'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot initial class distribution\n",
    "plot_class_distribution(labels, \"Class Distribution Before Augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add GCN Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define WGAN Generator and Discriminator\n",
    "class WGANGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(WGANGenerator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = torch.relu(self.fc1(z))\n",
    "        return self.fc2(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(WGANDiscriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGAN parameters\n",
    "input_size = node_features.shape[1]\n",
    "hidden_size = 128\n",
    "output_size = input_size\n",
    "latent_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WGAN components\n",
    "generator = WGANGenerator(latent_size, hidden_size, output_size)\n",
    "discriminator = WGANDiscriminator(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0001)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute statistics: mean, variance, and standard deviation\n",
    "def compute_statistics(features):\n",
    "    mean = torch.mean(features, dim=0)\n",
    "    var = torch.var(features, dim=0)\n",
    "    std = torch.std(features, dim=0)\n",
    "    return mean, var, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Mean: tensor([2.3957e-03, 6.2278e+00, 4.4526e+02, 2.6677e+01]), Initial Variance: tensor([3.0670e-05, 1.5315e+01, 6.6874e+04, 2.0538e+02]), Initial Std Dev: tensor([5.5381e-03, 3.9134e+00, 2.5860e+02, 1.4331e+01])\n"
     ]
    }
   ],
   "source": [
    "# Print initial statistics\n",
    "initial_mean, initial_var, initial_std = compute_statistics(node_features)\n",
    "print(f\"Initial Mean: {initial_mean}, Initial Variance: {initial_var}, Initial Std Dev: {initial_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with early stopping\n",
    "num_epochs = 16\n",
    "target_minority_class = torch.sum(labels == 0)\n",
    "real_data = node_features[labels == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "best_loss_d = float('inf')\n",
    "patience = 1\n",
    "trigger_times = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-cd37cf9fcfb0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0md_fake\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfake_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss_d\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_real\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_fake\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer_d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    current_minority_count = torch.sum(labels == 1)\n",
    "    if current_minority_count >= target_minority_class:\n",
    "        break\n",
    "\n",
    "    # Update the discriminator 5 times for every generator update\n",
    "    for _ in range(5):\n",
    "        z = torch.randn(real_data.size(0), latent_size)\n",
    "        fake_data = generator(z)\n",
    "\n",
    "        optimizer_d.zero_grad()\n",
    "        d_real = discriminator(real_data)\n",
    "        d_fake = discriminator(fake_data)\n",
    "        loss_d = -torch.mean(d_real) + torch.mean(d_fake)\n",
    "        loss.backward(retain_graph=True)\n",
    "\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Clip weights\n",
    "        for p in discriminator.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "    optimizer_g.zero_grad()\n",
    "    fake_data = generator(torch.randn(real_data.size(0), latent_size))\n",
    "    loss_g = -torch.mean(discriminator(fake_data))\n",
    "    loss_g.backward()\n",
    "    optimizer_g.step()\n",
    "\n",
    "    # Update labels based on newly generated samples\n",
    "    labels = torch.cat((labels, torch.zeros(fake_data.size(0), dtype=torch.long)))\n",
    "    node_features = torch.cat((node_features, fake_data))\n",
    "\n",
    "    # Early stopping check\n",
    "    if loss_d.item() < best_loss_d:\n",
    "        best_loss_d = loss_d.item()\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "\n",
    "    if trigger_times >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss D: {loss_d.item()}, Loss G: {loss_g.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate enough samples to match the class distribution\n",
    "num_generated_samples = target_minority_class - current_minority_count\n",
    "generated_data = generator(torch.randn(num_generated_samples, latent_size))\n",
    "y_generated = torch.ones(num_generated_samples, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine generated data with the original data\n",
    "x_augmented = torch.cat([node_features, generated_data], dim=0)\n",
    "y_augmented = torch.cat([labels, y_generated], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot augmented class distribution\n",
    "plot_class_distribution(y_augmented, \"Class Distribution After Augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print final statistics\n",
    "final_mean, final_var, final_std = compute_statistics(x_augmented)\n",
    "print(f\"Final Mean: {final_mean}, Final Variance: {final_var}, Final Std Dev: {final_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming real_data is your actual node features labeled as fraud (real minority class)\n",
    "real_data = node_features[labels == 1]  # Take only fraud samples (minority class)\n",
    "\n",
    "# If generated_data has more samples than real_data, we need to match their size\n",
    "min_size = min(real_data.size(0), generated_data.size(0))\n",
    "\n",
    "# Subsample real and generated data to have the same number of rows\n",
    "real_data_sampled = real_data[:min_size]\n",
    "generated_data_sampled = generated_data[:min_size]\n",
    "\n",
    "# Function to compute R-squared\n",
    "def r_squared(real_data, generated_data):\n",
    "    ss_res = torch.sum((real_data - generated_data) ** 2, dim=0)  # Residual sum of squares\n",
    "    ss_tot = torch.sum((real_data - torch.mean(real_data, dim=0)) ** 2, dim=0)  # Total sum of squares\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute R-squared between the real and generated data samples\n",
    "r2_scores = r_squared(real_data_sampled, generated_data_sampled)\n",
    "print(f\"R-squared for each feature: {r2_scores}\")\n",
    "print(f\"Mean R-squared: {r2_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate MCC\n",
    "def calculate_mcc(y_true, y_pred):\n",
    "    # Convert PyTorch tensors to NumPy arrays after detaching from the graph\n",
    "    y_true_np = y_true.detach().cpu().numpy()  # Detach and move to CPU if necessary\n",
    "    y_pred_np = y_pred.detach().cpu().numpy()  # Detach and move to CPU if necessary\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true_np, y_pred_np).ravel()\n",
    "\n",
    "    # Convert confusion matrix components to PyTorch tensors\n",
    "    tp = torch.tensor(tp, dtype=torch.float)\n",
    "    tn = torch.tensor(tn, dtype=torch.float)\n",
    "    fp = torch.tensor(fp, dtype=torch.float)\n",
    "    fn = torch.tensor(fn, dtype=torch.float)\n",
    "\n",
    "    # Apply MCC formula\n",
    "    numerator = (tp * tn) - (fp * fn)\n",
    "    denominator = torch.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    if denominator == 0:\n",
    "        return 0  # Handle division by zero\n",
    "    else:\n",
    "        mcc = numerator / denominator\n",
    "        return mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume you have binary predictions from the discriminator\n",
    "real_data_labels = labels  # Known 'is_fraud' labels (0 or 1)\n",
    "generated_labels = torch.round(discriminator(generated_data_sampled))  # Detach here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both real and generated labels have the same size\n",
    "real_data_labels_sampled = real_data_labels[:min_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate MCC\n",
    "mcc = calculate_mcc(real_data_labels_sampled, generated_labels)\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to calculate all metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Convert PyTorch tensors to NumPy arrays after detaching from the graph\n",
    "    y_true_np = y_true.detach().cpu().numpy()  # Detach and move to CPU if necessary\n",
    "    y_pred_np = y_pred.detach().cpu().numpy()  # Detach and move to CPU if necessary\n",
    "    \n",
    "    # Calculate accuracy, precision, recall, and F1 score\n",
    "    accuracy = accuracy_score(y_true_np, y_pred_np)\n",
    "    precision = precision_score(y_true_np, y_pred_np)\n",
    "    recall = recall_score(y_true_np, y_pred_np)\n",
    "    f1 = f1_score(y_true_np, y_pred_np)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Calculate metrics for the real and generated data labels\n",
    "accuracy, precision, recall, f1 = calculate_metrics(real_data_labels_sampled, generated_labels)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split Data into Train and Test\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(node_features, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Classifier Model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Classifier on Balanced Dataset\n",
    "classifier = Classifier(input_size, hidden_size)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "train_losses, test_losses = [], []\n",
    "train_accuracies, test_accuracies = [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "\n",
    "# Classifier Training Loop\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(30):\n",
    "    # Training phase\n",
    "    classifier.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass and backpropagation\n",
    "    y_pred = classifier(x_train)\n",
    "    loss = loss_fn(y_pred, y_train)\n",
    "    loss.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Detach loss for recording and release computation graph\n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    # Switch to evaluation mode for accuracy calculation\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        # Training accuracy\n",
    "        y_pred_train = classifier(x_train)\n",
    "        train_accuracy = accuracy_score(y_train.cpu().numpy(), y_pred_train.argmax(dim=1).cpu().numpy())\n",
    "        train_accuracies.append(train_accuracy)\n",
    "        \n",
    "        # Testing loss and accuracy\n",
    "        y_test_pred = classifier(x_test)\n",
    "        test_loss = loss_fn(y_test_pred, y_test)\n",
    "        test_losses.append(test_loss.item())\n",
    "        test_accuracy = accuracy_score(y_test.cpu().numpy(), y_test_pred.argmax(dim=1).cpu().numpy())\n",
    "        test_accuracies.append(test_accuracy)\n",
    "    \n",
    "    # Print stats every 5 epochs\n",
    "    if epoch % 5 == 0:\n",
    "        print(f'Epoch {epoch}, Train Loss: {loss.item():.4f}, Test Loss: {test_loss.item():.4f}, '\n",
    "              f'Train Acc: {train_accuracy:.4f}, Test Acc: {test_accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Train-Test Accuracy Curve\n",
    "plt.figure()\n",
    "plt.plot(train_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(test_accuracies, label=\"Test Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Train-Test Accuracy Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Train-Test Loss Curve\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label=\"Train Loss\")\n",
    "plt.plot(test_losses, label=\"Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Train-Test Loss Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Confusion Matrix and ROC-AUC\n",
    "y_test_pred = classifier(x_test).argmax(dim=1)\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC AUC Score\n",
    "with torch.no_grad():  # Ensure gradients are not being tracked\n",
    "    y_test_proba = torch.softmax(classifier(x_test), dim=1)[:, 1].detach().numpy()\n",
    "    roc_auc = roc_auc_score(y_test.numpy(), y_test_proba)\n",
    "    fpr, tpr, _ = roc_curve(y_test.numpy(), y_test_proba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ROC AUC Curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.2f})\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.legend()\n",
    "plt.title(\"ROC AUC Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
