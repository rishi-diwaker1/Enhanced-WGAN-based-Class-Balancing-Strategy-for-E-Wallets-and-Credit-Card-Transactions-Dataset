{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F\n",
    "\n",
    "# GCN Layer Implementation\n",
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        # Normalize adjacency matrix\n",
    "        deg = torch.sum(adj, dim=1)\n",
    "        deg_inv_sqrt = torch.pow(deg, -0.5)\n",
    "        deg_inv_sqrt[torch.isinf(deg_inv_sqrt)] = 0\n",
    "        norm_adj = torch.diag(deg_inv_sqrt) @ adj @ torch.diag(deg_inv_sqrt)\n",
    "        \n",
    "        # GCN propagation rule\n",
    "        support = self.linear(x)\n",
    "        output = torch.matmul(norm_adj, support)\n",
    "        return output\n",
    "\n",
    "# Enhanced Generator with GCN layers\n",
    "class GCNGenerator(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, node_features, num_nodes):\n",
    "        super(GCNGenerator, self).__init__()\n",
    "        \n",
    "        self.num_nodes = num_nodes\n",
    "        self.node_features = node_features\n",
    "        \n",
    "        # Initial linear layers for latent vector\n",
    "        self.fc1 = nn.Linear(latent_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, num_nodes * hidden_size)\n",
    "        \n",
    "        # GCN layers\n",
    "        self.gcn1 = GCNLayer(hidden_size, hidden_size)\n",
    "        self.gcn2 = GCNLayer(hidden_size, hidden_size)\n",
    "        self.gcn3 = GCNLayer(hidden_size, node_features)\n",
    "        \n",
    "        # Batch normalization layers\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "    def forward(self, z, adj):\n",
    "        # Initial shape transformation\n",
    "        x = F.relu(self.fc1(z))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = x.view(-1, self.num_nodes, x.size(1) // self.num_nodes)\n",
    "        \n",
    "        # Apply GCN layers with residual connections\n",
    "        x1 = F.relu(self.bn1(self.gcn1(x, adj).transpose(1, 2)).transpose(1, 2))\n",
    "        x2 = F.relu(self.bn2(self.gcn2(x1, adj).transpose(1, 2)).transpose(1, 2))\n",
    "        x3 = self.gcn3(x2, adj)\n",
    "        \n",
    "        return torch.sigmoid(x3)\n",
    "\n",
    "# Enhanced Discriminator with GCN layers\n",
    "class GCNDiscriminator(nn.Module):\n",
    "    def __init__(self, node_features, hidden_size, num_nodes):\n",
    "        super(GCNDiscriminator, self).__init__()\n",
    "        \n",
    "        # GCN layers\n",
    "        self.gcn1 = GCNLayer(node_features, hidden_size)\n",
    "        self.gcn2 = GCNLayer(hidden_size, hidden_size)\n",
    "        \n",
    "        # Final classification layers\n",
    "        self.fc1 = nn.Linear(hidden_size * num_nodes, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "        # Batch normalization layers\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size)\n",
    "        \n",
    "    def forward(self, x, adj):\n",
    "        # Apply GCN layers\n",
    "        x1 = F.relu(self.bn1(self.gcn1(x, adj).transpose(1, 2)).transpose(1, 2))\n",
    "        x2 = F.relu(self.bn2(self.gcn2(x1, adj).transpose(1, 2)).transpose(1, 2))\n",
    "        \n",
    "        # Flatten and apply final layers\n",
    "        x3 = x2.view(x2.size(0), -1)\n",
    "        x4 = F.relu(self.fc1(x3))\n",
    "        return torch.sigmoid(self.fc2(x4))\n",
    "\n",
    "# Data preprocessing functions remain the same as in your code\n",
    "def df_label_encoder(df, columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    df = df_label_encoder(df, ['nameOrig', 'nameDest', 'type'])\n",
    "    df['amount'] = (df['amount'] - df['amount'].min()) / (df['amount'].max() - df['amount'].min())\n",
    "    df['node_from'] = df['nameOrig'].astype(str)\n",
    "    df['node_to'] = df['nameDest'].astype(str)\n",
    "    df = df.sort_values(by=['node_from'])\n",
    "    node_list = pd.concat([df['node_from'], df['node_to']]).unique()\n",
    "    return df, node_list\n",
    "\n",
    "def create_graph_data(df, node_list):\n",
    "    node_map = {node: idx for idx, node in enumerate(node_list)}\n",
    "    \n",
    "    # Create edge index\n",
    "    edge_index = np.array([\n",
    "        [node_map[from_node], node_map[to_node]] \n",
    "        for from_node, to_node in zip(df['node_from'], df['node_to'])\n",
    "    ], dtype=np.int64).T\n",
    "    \n",
    "    # Create adjacency matrix\n",
    "    num_nodes = len(node_list)\n",
    "    adj = torch.zeros((num_nodes, num_nodes))\n",
    "    adj[edge_index[0], edge_index[1]] = 1\n",
    "    \n",
    "    # Make adjacency matrix symmetric (undirected graph)\n",
    "    adj = adj + adj.t()\n",
    "    adj[adj > 1] = 1\n",
    "    \n",
    "    # Add self-loops\n",
    "    adj = adj + torch.eye(num_nodes)\n",
    "    \n",
    "    # Create node features\n",
    "    node_features = torch.tensor(df[['amount', 'type']].values, dtype=torch.float)\n",
    "    \n",
    "    # Labels\n",
    "    labels = torch.tensor(df['isFraud'].values, dtype=torch.long)\n",
    "    \n",
    "    return node_features, adj, labels\n",
    "\n",
    "# Training function\n",
    "def train_gcn_gan(generator, discriminator, node_features, adj, labels, num_epochs=100):\n",
    "    # Initialize optimizers\n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "    criterion = nn.BCELoss()\n",
    "    \n",
    "    # Training statistics\n",
    "    g_losses = []\n",
    "    d_losses = []\n",
    "    \n",
    "    num_nodes = node_features.size(0)\n",
    "    latent_size = 64\n",
    "    batch_size = 32\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Train Discriminator\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        # Real data\n",
    "        real_labels = torch.ones(batch_size, 1)\n",
    "        d_real = discriminator(node_features.unsqueeze(0).expand(batch_size, -1, -1), adj)\n",
    "        d_real_loss = criterion(d_real, real_labels)\n",
    "        \n",
    "        # Fake data\n",
    "        z = torch.randn(batch_size, latent_size)\n",
    "        fake_features = generator(z, adj)\n",
    "        fake_labels = torch.zeros(batch_size, 1)\n",
    "        d_fake = discriminator(fake_features, adj)\n",
    "        d_fake_loss = criterion(d_fake, fake_labels)\n",
    "        \n",
    "        # Combined discriminator loss\n",
    "        d_loss = d_real_loss + d_fake_loss\n",
    "        d_loss.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # Train Generator\n",
    "        optimizer_g.zero_grad()\n",
    "        \n",
    "        z = torch.randn(batch_size, latent_size)\n",
    "        fake_features = generator(z, adj)\n",
    "        g_fake = discriminator(fake_features, adj)\n",
    "        g_loss = criterion(g_fake, real_labels)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        # Record losses\n",
    "        g_losses.append(g_loss.item())\n",
    "        d_losses.append(d_loss.item())\n",
    "        \n",
    "        if epoch % 10 == 0:\n",
    "            print(f'Epoch [{epoch}/{num_epochs}], D Loss: {d_loss.item():.4f}, G Loss: {g_loss.item():.4f}')\n",
    "    \n",
    "    return g_losses, d_losses\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess data\n",
    "    df = pd.read_csv('paysim/paysim.csv')\n",
    "    df = df.sample(frac=0.2, random_state=42).reset_index(drop=True)\n",
    "    df, node_list = preprocess(df)\n",
    "    node_features, adj, labels = create_graph_data(df, node_list)\n",
    "    \n",
    "    # Initialize models\n",
    "    num_nodes = len(node_list)\n",
    "    node_feature_size = node_features.size(1)\n",
    "    hidden_size = 128\n",
    "    latent_size = 64\n",
    "    \n",
    "    generator = GCNGenerator(latent_size, hidden_size, node_feature_size, num_nodes)\n",
    "    discriminator = GCNDiscriminator(node_feature_size, hidden_size, num_nodes)\n",
    "    \n",
    "    # Train the model\n",
    "    g_losses, d_losses = train_gcn_gan(generator, discriminator, node_features, adj, labels)\n",
    "    \n",
    "    # Plot training losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(g_losses, label='Generator Loss')\n",
    "    plt.plot(d_losses, label='Discriminator Loss')\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.title('GCN-GAN Training Losses')\n",
    "    plt.show()\n",
    "    \n",
    "    # Generate synthetic samples\n",
    "    with torch.no_grad():\n",
    "        z = torch.randn(32, latent_size)\n",
    "        synthetic_features = generator(z, adj)\n",
    "        \n",
    "    print(\"Synthetic features shape:\", synthetic_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
