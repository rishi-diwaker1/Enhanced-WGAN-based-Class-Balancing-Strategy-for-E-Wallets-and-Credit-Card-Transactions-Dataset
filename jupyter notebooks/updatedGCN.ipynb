{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girishkk/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing and Label Encoding\n",
    "def df_label_encoder(df, columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the dataset and extract features for node creation\n",
    "def preprocess(df):\n",
    "    df = df_label_encoder(df, ['merchant', 'category', 'city', 'state', 'job'])\n",
    "    df['amt'] = (df['amt'] - df['amt'].min()) / (df['amt'].max() - df['amt'].min())\n",
    "    df['node_from'] = df['cc_num'].astype(str)\n",
    "    df['node_to'] = df['merchant'].astype(str)\n",
    "    df = df.sort_values(by=['node_from'])\n",
    "    node_list = pd.concat([df['node_from'], df['node_to']]).unique()\n",
    "    return df, node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_graph_data(df, node_list):\n",
    "    # Create a mapping of node names to indices\n",
    "    node_map = {node: idx for idx, node in enumerate(node_list)}\n",
    "    \n",
    "    # Convert edges to indices\n",
    "    edge_index = np.array([\n",
    "        [node_map[from_node], node_map[to_node]] for from_node, to_node in zip(df['node_from'], df['node_to'])\n",
    "    ], dtype=np.int64).T  # Transpose to get the shape [2, num_edges]\n",
    "\n",
    "    # Node features (converted to numpy array or tensor)\n",
    "    node_features = torch.tensor(df[['amt', 'category', 'city', 'state']].values, dtype=torch.float32)\n",
    "\n",
    "    # Labels (0 for non-fraud, 1 for fraud)\n",
    "    labels = torch.tensor(df['is_fraud'].values, dtype=torch.long)\n",
    "\n",
    "    return node_features, edge_index, labels, node_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and preprocess\n",
    "df = pd.read_csv('creditcard/fraudTrain.csv')  # Update with your .csv file path\n",
    "df, node_list = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_features, edge_index, labels, node_map = create_graph_data(df, node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "def plot_class_distribution(y_data, title):\n",
    "    classes, counts = torch.unique(y_data, return_counts=True)\n",
    "    plt.bar(classes.numpy(), counts.numpy())\n",
    "    plt.title(title)\n",
    "    plt.xticks([0, 1], ['Non-Fraud', 'Fraud'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_class_distribution(labels, \"Class Distribution Before Augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adjacency_matrix(edge_index, num_nodes):\n",
    "    # Use a sparse tensor if the graph is large\n",
    "    adj = torch.zeros((num_nodes, num_nodes), dtype=torch.float32)  # For unweighted edges\n",
    "\n",
    "    # Efficiently assign edges\n",
    "    row_indices = edge_index[0].long()  # Ensure indices are of type long\n",
    "    col_indices = edge_index[1].long()\n",
    "    \n",
    "    adj[row_indices, col_indices] = 1  # Set values to 1 for edges\n",
    "\n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_adj(adj):\n",
    "    degree = torch.sum(adj, dim=1)  # Compute degree (sum of rows)\n",
    "    degree_inv_sqrt = torch.diag(torch.pow(degree, -0.5))\n",
    "    adj_normalized = degree_inv_sqrt @ adj @ degree_inv_sqrt  # Symmetric normalization\n",
    "    return adj_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement GCN layer manually\n",
    "class SimpleGCNLayer(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(SimpleGCNLayer, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "    \n",
    "    def forward(self, x, adj):\n",
    "        x = torch.relu(self.fc(adj @ x))  # Graph convolution using dense adjacency matrix\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, out_features)\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        # Graph convolution: x' = ReLU(Adjacency_matrix * x * Weights)\n",
    "        x = torch.matmul(adj, x)  # Multiply adjacency matrix by input feature matrix\n",
    "        x = self.fc(x)  # Apply the linear transformation (weights)\n",
    "        return torch.relu(x)  # Apply ReLU activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANGeneratorWithManualGCN(nn.Module):\n",
    "    def __init__(self, latent_size, hidden_size, output_size, num_nodes, adj):\n",
    "        super(WGANGeneratorWithManualGCN, self).__init__()\n",
    "        self.latent_size = latent_size\n",
    "        self.fc1 = nn.Linear(latent_size, hidden_size)\n",
    "        self.gcn1 = GCNLayer(hidden_size, hidden_size)  # GCN Layer 1\n",
    "        self.gcn2 = GCNLayer(hidden_size, hidden_size)  # GCN Layer 2\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.adj = adj  # Store adjacency matrix (should be in the correct format)\n",
    "        self.num_nodes = num_nodes  # Total number of nodes in the graph\n",
    "\n",
    "    def forward(self, z):\n",
    "        # Pass through the first fully connected layer\n",
    "        z = torch.relu(self.fc1(z))\n",
    "        \n",
    "        # Create sparse adjacency matrix\n",
    "        adj = self.build_sparse_adjacency_matrix(self.adj, self.num_nodes)\n",
    "        adj = self.normalize_sparse_adj(adj)  # Normalize the adjacency matrix\n",
    "        z = z[:self.num_nodes]  # Adjust size of z to match the number of nodes\n",
    "        \n",
    "        # Pass through GCN layers\n",
    "        z = self.gcn1(z, adj)  # Graph convolution using the expanded adjacency matrix\n",
    "        z = self.gcn2(z, adj)\n",
    "        \n",
    "        # Final output layer\n",
    "        return self.fc2(z)\n",
    "\n",
    "    def build_sparse_adjacency_matrix(self, edge_index):\n",
    "        # Ensure edge_index is a LongTensor with shape (2, num_edges)\n",
    "        if isinstance(edge_index, torch.Tensor):\n",
    "            edge_index = edge_index.long()  # Ensure it's a LongTensor\n",
    "        else:\n",
    "            edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "\n",
    "        # Transpose edge_index to shape (2, num_edges)\n",
    "        indices = edge_index.t()  # Transpose to get the right shape\n",
    "\n",
    "        # Values should be 1s for unweighted edges\n",
    "        values = torch.ones(indices.shape[1], dtype=torch.float32)  # Values match number of edges\n",
    "\n",
    "        # Create the sparse adjacency matrix\n",
    "        adj_sparse = torch.sparse_coo_tensor(indices, values, (self.num_nodes, self.num_nodes))\n",
    "        return adj_sparse\n",
    "\n",
    "    def normalize_sparse_adj(self, adj):\n",
    "        # Compute degree matrix\n",
    "        degree = torch.sparse.sum(adj, dim=1).to_dense()\n",
    "        degree_inv_sqrt = torch.pow(degree, -0.5)\n",
    "        degree_inv_sqrt[torch.isinf(degree_inv_sqrt)] = 0  # Avoid division by zero\n",
    "\n",
    "        # Apply normalization: D^(-1/2) * A * D^(-1/2)\n",
    "        adj_normalized = adj.coalesce()  # Ensures indices are sorted, necessary for sparse tensor operations\n",
    "        adj_normalized = adj_normalized * degree_inv_sqrt.unsqueeze(0) * degree_inv_sqrt.unsqueeze(1)\n",
    "        return adj_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(WGANDiscriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "        self.leaky_relu = nn.LeakyReLU(0.2)  # LeakyReLU for better gradient flow\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky_relu(self.fc1(x))\n",
    "        return self.fc2(x)  # No activation, return raw score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGAN training\n",
    "def train_wgan(generator, discriminator, num_epochs, data_loader, d_optimizer, g_optimizer, z_dim, device):\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, data in enumerate(data_loader):\n",
    "            real_data = data.to(device)\n",
    "\n",
    "            # Train Discriminator\n",
    "            d_optimizer.zero_grad()\n",
    "            z = torch.randn(real_data.size(0), z_dim).to(device)  # Latent vector\n",
    "            fake_data = generator(z).detach()  # Generate fake data and detach\n",
    "            real_loss = discriminator(real_data).mean()\n",
    "            fake_loss = discriminator(fake_data).mean()\n",
    "            d_loss = fake_loss - real_loss\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "            # Train Generator\n",
    "            g_optimizer.zero_grad()\n",
    "            fake_data = generator(z)  # Generate fake data\n",
    "            g_loss = -discriminator(fake_data).mean()  # Generator loss\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            # Logging\n",
    "            if (i + 1) % 100 == 0:\n",
    "                print(f\"Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(data_loader)}], D Loss: {d_loss.item()}, G Loss: {g_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_size = 64  # Latent space dimension\n",
    "hidden_size = 64   # Hidden layer size\n",
    "output_size = node_features.size(1)  # Output size matches the input feature size\n",
    "num_nodes = node_features.size(0)  # Number of nodes in the graph\n",
    "adj_matrix = build_adjacency_matrix(edge_index, num_nodes)  # Create the adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "generator = WGANGeneratorWithManualGCN(latent_size, hidden_size, output_size, num_nodes, adj_matrix).to(device)\n",
    "discriminator = WGANDiscriminator(output_size, hidden_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "d_optimizer = optim.RMSprop(discriminator.parameters(), lr=0.00005)\n",
    "g_optimizer = optim.RMSprop(generator.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Loader\n",
    "batch_size = 32\n",
    "data_loader = torch.utils.data.DataLoader(node_features, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the WGAN\n",
    "train_wgan(generator, discriminator, num_epochs=50, data_loader=data_loader, d_optimizer=d_optimizer, g_optimizer=g_optimizer, z_dim=latent_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data\n",
    "num_samples = 1000\n",
    "z = torch.randn(num_samples, latent_size).to(device)\n",
    "synthetic_data = generator(z).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame for analysis\n",
    "synthetic_df = pd.DataFrame(synthetic_data, columns=df.columns[:-1])  # Adjust columns if necessary\n",
    "synthetic_df['is_fraud'] = 1  # Set all synthetic data as fraud for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot synthetic data distribution\n",
    "plot_class_distribution(torch.tensor(synthetic_df['is_fraud'].values), \"Class Distribution of Synthetic Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
