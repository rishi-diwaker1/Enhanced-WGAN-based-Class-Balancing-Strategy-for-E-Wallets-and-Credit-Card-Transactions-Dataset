{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girishkk/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Data Preprocessing and Label Encoding\n",
    "def df_label_encoder(df, columns):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    df = df_label_encoder(df, ['nameOrig', 'nameDest', 'type'])\n",
    "    \n",
    "    # Normalize the 'amount' column\n",
    "    df['amount'] = (df['amount'] - df['amount'].min()) / (df['amount'].max() - df['amount'].min())\n",
    "    \n",
    "    # Create node_from and node_to based on 'nameOrig' and 'nameDest'\n",
    "    df['node_from'] = df['nameOrig'].astype(str)\n",
    "    df['node_to'] = df['nameDest'].astype(str)\n",
    "    \n",
    "    # Sort values based on origin nodes\n",
    "    df = df.sort_values(by=['node_from'])\n",
    "    \n",
    "    # Unique node list based on origin and destination\n",
    "    node_list = pd.concat([df['node_from'], df['node_to']]).unique()\n",
    "    \n",
    "    return df, node_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create graph data\n",
    "def create_graph_data(df, node_list):\n",
    "    # Create a mapping of node names to indices\n",
    "    node_map = {node: idx for idx, node in enumerate(node_list)}\n",
    "    \n",
    "    # Convert edges to indices\n",
    "    edge_index = np.array([\n",
    "        [node_map[from_node], node_map[to_node]] for from_node, to_node in zip(df['node_from'], df['node_to'])\n",
    "    ], dtype=np.int64).T  # Transpose to get shape [2, num_edges]\n",
    "\n",
    "    # Node features (transaction 'amount' only for simplicity; could include others like 'oldbalanceOrg', 'newbalanceOrig')\n",
    "    node_features = torch.tensor(df[['amount']].values, dtype=torch.float)\n",
    "\n",
    "    # Labels: 0 for non-fraud, 1 for fraud\n",
    "    labels = torch.tensor(df['isFraud'].values, dtype=torch.long)\n",
    "\n",
    "    return node_features, edge_index, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset and preprocess\n",
    "df = pd.read_csv('paysim/paysim.csv')  # Update with your .csv file path\n",
    "df, node_list = preprocess(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the graph dataset\n",
    "node_features, edge_index, labels = create_graph_data(df, node_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "def plot_class_distribution(y_data, title):\n",
    "    classes, counts = torch.unique(y_data, return_counts=True)\n",
    "    plt.bar(classes.numpy(), counts.numpy())\n",
    "    plt.title(title)\n",
    "    plt.xticks([0, 1], ['Non-Fraud', 'Fraud'])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot initial class distribution\n",
    "plot_class_distribution(labels, \"Class Distribution Before Augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define WGAN Generator and Discriminator\n",
    "class WGANGenerator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(WGANGenerator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = torch.relu(self.fc1(z))\n",
    "        return self.fc2(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WGANDiscriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(WGANDiscriminator, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WGAN parameters\n",
    "input_size = node_features.shape[1]\n",
    "hidden_size = 128\n",
    "output_size = input_size\n",
    "latent_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize WGAN components\n",
    "generator = WGANGenerator(latent_size, hidden_size, output_size)\n",
    "discriminator = WGANDiscriminator(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=0.0001)\n",
    "optimizer_d = optim.Adam(discriminator.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to compute statistics: mean, variance, and standard deviation\n",
    "def compute_statistics(features):\n",
    "    mean = torch.mean(features, dim=0)\n",
    "    var = torch.var(features, dim=0)\n",
    "    std = torch.std(features, dim=0)\n",
    "    return mean, var, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Mean: tensor([0.0019]), Initial Variance: tensor([4.2668e-05]), Initial Std Dev: tensor([0.0065])\n"
     ]
    }
   ],
   "source": [
    "# Print initial statistics\n",
    "initial_mean, initial_var, initial_std = compute_statistics(node_features)\n",
    "print(f\"Initial Mean: {initial_mean}, Initial Variance: {initial_var}, Initial Std Dev: {initial_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training with early stopping\n",
    "num_epochs = 16\n",
    "target_minority_class = torch.sum(labels == 0)\n",
    "real_data = node_features[labels == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping parameters\n",
    "best_loss_d = float('inf')\n",
    "patience = 1\n",
    "trigger_times = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0/16], Loss D: -1.9152648746967316e-05, Loss G: -0.00949722621589899\n",
      "Epoch [1/16], Loss D: -2.19615176320076e-05, Loss G: -0.009511825628578663\n",
      "Epoch [2/16], Loss D: -2.6685185730457306e-05, Loss G: -0.009518183767795563\n",
      "Epoch [3/16], Loss D: -3.06498259305954e-05, Loss G: -0.009531958028674126\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    current_minority_count = torch.sum(labels == 1)\n",
    "    if current_minority_count >= target_minority_class:\n",
    "        break\n",
    "\n",
    "    # Update the discriminator 5 times for every generator update\n",
    "    for _ in range(5):\n",
    "        z = torch.randn(real_data.size(0), latent_size)\n",
    "        fake_data = generator(z)\n",
    "\n",
    "        optimizer_d.zero_grad()\n",
    "        d_real = discriminator(real_data)\n",
    "        d_fake = discriminator(fake_data.detach())\n",
    "        loss_d = -torch.mean(d_real) + torch.mean(d_fake)\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "\n",
    "        # Clip weights\n",
    "        for p in discriminator.parameters():\n",
    "            p.data.clamp_(-0.01, 0.01)\n",
    "\n",
    "    optimizer_g.zero_grad()\n",
    "    fake_data = generator(torch.randn(real_data.size(0), latent_size))\n",
    "    loss_g = -torch.mean(discriminator(fake_data))\n",
    "    loss_g.backward()\n",
    "    optimizer_g.step()\n",
    "\n",
    "    # Update labels based on newly generated samples\n",
    "    labels = torch.cat((labels, torch.zeros(fake_data.size(0), dtype=torch.long)))\n",
    "    node_features = torch.cat((node_features, fake_data))\n",
    "\n",
    "    # Early stopping check\n",
    "    if loss_d.item() < best_loss_d:\n",
    "        best_loss_d = loss_d.item()\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "\n",
    "    if trigger_times >= patience:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss D: {loss_d.item()}, Loss G: {loss_g.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate enough samples to match the class distribution\n",
    "num_generated_samples = target_minority_class - current_minority_count\n",
    "generated_data = generator(torch.randn(num_generated_samples, latent_size))\n",
    "y_generated = torch.ones(num_generated_samples, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine generated data with the original data\n",
    "x_augmented = torch.cat([node_features, generated_data], dim=0)\n",
    "y_augmented = torch.cat([labels, y_generated], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot augmented class distribution\n",
    "plot_class_distribution(y_augmented, \"Class Distribution After Augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Mean: tensor([-0.0037], grad_fn=<MeanBackward1>), Final Variance: tensor([0.0173], grad_fn=<VarBackward0>), Final Std Dev: tensor([0.1315], grad_fn=<StdBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Print final statistics\n",
    "final_mean, final_var, final_std = compute_statistics(x_augmented)\n",
    "print(f\"Final Mean: {final_mean}, Final Variance: {final_var}, Final Std Dev: {final_std}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming real_data is your actual node features labeled as fraud (real minority class)\n",
    "real_data = node_features[labels == 1]  # Take only fraud samples (minority class)\n",
    "\n",
    "# If generated_data has more samples than real_data, we need to match their size\n",
    "min_size = min(real_data.size(0), generated_data.size(0))\n",
    "\n",
    "# Subsample real and generated data to have the same number of rows\n",
    "real_data_sampled = real_data[:min_size]\n",
    "generated_data_sampled = generated_data[:min_size]\n",
    "\n",
    "# Function to compute R-squared\n",
    "def r_squared(real_data, generated_data):\n",
    "    ss_res = torch.sum((real_data - generated_data) ** 2, dim=0)  # Residual sum of squares\n",
    "    ss_tot = torch.sum((real_data - torch.mean(real_data, dim=0)) ** 2, dim=0)  # Total sum of squares\n",
    "    r2 = 1 - (ss_res / ss_tot)\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared for each feature: tensor([-50.8826], grad_fn=<RsubBackward1>)\n",
      "Mean R-squared: -50.882625579833984\n"
     ]
    }
   ],
   "source": [
    "# Compute R-squared between the real and generated data samples\n",
    "r2_scores = r_squared(real_data_sampled, generated_data_sampled)\n",
    "print(f\"R-squared for each feature: {r2_scores}\")\n",
    "print(f\"Mean R-squared: {r2_scores.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate MCC\n",
    "def calculate_mcc(y_true, y_pred):\n",
    "    # Convert PyTorch tensors to NumPy arrays after detaching from the graph\n",
    "    y_true_np = y_true.detach().cpu().numpy()  # Detach and move to CPU if necessary\n",
    "    y_pred_np = y_pred.detach().cpu().numpy()  # Detach and move to CPU if necessary\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true_np, y_pred_np).ravel()\n",
    "\n",
    "    # Convert confusion matrix components to PyTorch tensors\n",
    "    tp = torch.tensor(tp, dtype=torch.float)\n",
    "    tn = torch.tensor(tn, dtype=torch.float)\n",
    "    fp = torch.tensor(fp, dtype=torch.float)\n",
    "    fn = torch.tensor(fn, dtype=torch.float)\n",
    "\n",
    "    # Apply MCC formula\n",
    "    numerator = (tp * tn) - (fp * fn)\n",
    "    denominator = torch.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))\n",
    "\n",
    "    if denominator == 0:\n",
    "        return 0  # Handle division by zero\n",
    "    else:\n",
    "        mcc = numerator / denominator\n",
    "        return mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's assume you have binary predictions from the discriminator\n",
    "real_data_labels = labels  # Known 'is_fraud' labels (0 or 1)\n",
    "generated_labels = torch.round(discriminator(generated_data_sampled)).detach()  # Detach here as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure both real and generated labels have the same size\n",
    "real_data_labels_sampled = real_data_labels[:min_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matthews Correlation Coefficient (MCC): 0.6855089444\n"
     ]
    }
   ],
   "source": [
    "# Calculate MCC\n",
    "mcc = calculate_mcc(real_data_labels_sampled, generated_labels)\n",
    "print(f\"Matthews Correlation Coefficient (MCC): {mcc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9988\n",
      "Precision: 0.9145\n",
      "Recall: 0.9272\n",
      "F1 Score: 0.9204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girishkk/.local/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Function to calculate all metrics\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    # Convert PyTorch tensors to NumPy arrays after detaching from the graph\n",
    "    y_true_np = y_true.detach().cpu().numpy()  # Detach and move to CPU if necessary\n",
    "    y_pred_np = y_pred.detach().cpu().numpy()  # Detach and move to CPU if necessary\n",
    "    \n",
    "    # Calculate accuracy, precision, recall, and F1 score\n",
    "    accuracy = accuracy_score(y_true_np, y_pred_np)\n",
    "    precision = precision_score(y_true_np, y_pred_np)\n",
    "    recall = recall_score(y_true_np, y_pred_np)\n",
    "    f1 = f1_score(y_true_np, y_pred_np)\n",
    "    \n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Calculate metrics for the real and generated data labels\n",
    "accuracy, precision, recall, f1 = calculate_metrics(real_data_labels_sampled, generated_labels)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girishkk/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jensen-Shannon Divergence (Mode Collapse Score): 0.2054\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from scipy.spatial.distance import jensenshannon\n",
    "\n",
    "def calculate_jsd(true_data, generated_data, bins=100):\n",
    "    \"\"\"\n",
    "    Compute the Jensen-Shannon Divergence (JSD) between the true and generated data distributions.\n",
    "    \n",
    "    :param true_data: Tensor or numpy array containing the true data.\n",
    "    :param generated_data: Tensor or numpy array containing the generated data.\n",
    "    :param bins: Number of bins to discretize the data.\n",
    "    \n",
    "    :return: Jensen-Shannon Divergence value.\n",
    "    \"\"\"\n",
    "    # Flatten and convert to numpy arrays\n",
    "    true_data = true_data.flatten().cpu().detach().numpy()\n",
    "    generated_data = generated_data.flatten().cpu().detach().numpy()\n",
    "    \n",
    "    # Compute the histograms for true and generated data\n",
    "    true_hist, _ = np.histogram(true_data, bins=bins, density=True)\n",
    "    gen_hist, _ = np.histogram(generated_data, bins=bins, density=True)\n",
    "    \n",
    "    # Add a small value to avoid zero probabilities (log(0) issue)\n",
    "    epsilon = 1e-8\n",
    "    true_hist = np.clip(true_hist, epsilon, 1.0)\n",
    "    gen_hist = np.clip(gen_hist, epsilon, 1.0)\n",
    "    \n",
    "    # Normalize histograms to ensure they sum to 1\n",
    "    true_hist /= true_hist.sum()\n",
    "    gen_hist /= gen_hist.sum()\n",
    "    \n",
    "    # Compute the Jensen-Shannon Divergence\n",
    "    jsd = jensenshannon(true_hist, gen_hist)\n",
    "    \n",
    "    return jsd\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Simulate some data for testing\n",
    "    true_data = torch.randn(1000)  # Example true data (e.g., real samples)\n",
    "    generated_data = torch.randn(1000)  # Example generated data (e.g., fake samples)\n",
    "    \n",
    "    jsd_score = calculate_jsd(true_data, generated_data, bins=100)\n",
    "    print(f\"Jensen-Shannon Divergence (Mode Collapse Score): {jsd_score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
