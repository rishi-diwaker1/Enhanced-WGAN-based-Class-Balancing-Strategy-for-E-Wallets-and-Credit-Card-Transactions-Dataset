{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/girishkk/.local/lib/python3.6/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading and preprocessing data...\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initializing models...\n",
      "\n",
      "Starting training...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (7506x4 and 128x4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-01657a69ae3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-01657a69ae3d>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    304\u001b[0m     generator, discriminator, augmented_features, augmented_labels, metrics_history = train_gan(\n\u001b[1;32m    305\u001b[0m         \u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m         \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlatent_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlatent_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m     )\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-01657a69ae3d>\u001b[0m in \u001b[0;36mtrain_gan\u001b[0;34m(generator, discriminator, node_features, edge_index, labels, num_epochs, latent_size, batch_size)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m         \u001b[0;31m# Real data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m         \u001b[0md_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreal_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m         \u001b[0mreal_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_real\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[0mloss_real\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_real\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-01657a69ae3d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgat1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-01657a69ae3d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Prepare edge features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-01657a69ae3d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m         \u001b[0mH\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_heads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;31m# Prepare edge features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1846\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1847\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (7506x4 and 128x4)"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, r2_score, matthews_corrcoef\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data preprocessing functions\n",
    "def df_label_encoder(df, columns):\n",
    "    \"\"\"Encode categorical columns using LabelEncoder\"\"\"\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    for col in columns:\n",
    "        df[col] = le.fit_transform(df[col].astype(str))\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    \"\"\"Preprocess the dataset and extract features for node creation\"\"\"\n",
    "    # Encode categorical columns\n",
    "    df = df_label_encoder(df, ['merchant', 'category', 'city', 'state', 'job'])\n",
    "    \n",
    "    # Normalize amount column\n",
    "    df['amt'] = (df['amt'] - df['amt'].min()) / (df['amt'].max() - df['amt'].min())\n",
    "    \n",
    "    # Create node mappings\n",
    "    df['node_from'] = df['cc_num'].astype(str)\n",
    "    df['node_to'] = df['merchant'].astype(str)\n",
    "    df = df.sort_values(by=['node_from'])\n",
    "    \n",
    "    # Get unique nodes\n",
    "    node_list = pd.concat([df['node_from'], df['node_to']]).unique()\n",
    "    return df, node_list\n",
    "\n",
    "def create_graph_data(df, node_list):\n",
    "    \"\"\"Create graph data structures from DataFrame\"\"\"\n",
    "    # Create node mapping\n",
    "    node_map = {node: idx for idx, node in enumerate(node_list)}\n",
    "    \n",
    "    # Create edge index\n",
    "    edge_index = np.array([\n",
    "        [node_map[from_node], node_map[to_node]] \n",
    "        for from_node, to_node in zip(df['node_from'], df['node_to'])\n",
    "    ], dtype=np.int64).T\n",
    "    \n",
    "    # Convert to torch tensors\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long)\n",
    "    node_features = torch.tensor(df[['amt', 'category', 'city', 'state']].values, dtype=torch.float)\n",
    "    labels = torch.tensor(df['is_fraud'].values, dtype=torch.long)\n",
    "    \n",
    "    return node_features, edge_index, labels\n",
    "\n",
    "class GATLayer(nn.Module):\n",
    "    \"\"\"Graph Attention Layer\"\"\"\n",
    "    def __init__(self, in_features, out_features, n_heads=4, dropout=0.6, alpha=0.2):\n",
    "        super(GATLayer, self).__init__()\n",
    "        self.dropout = dropout\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.n_heads = n_heads\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # Linear transformation for each attention head\n",
    "        self.W = nn.Parameter(torch.zeros(size=(n_heads, in_features, out_features)))\n",
    "        nn.init.xavier_uniform_(self.W.data, gain=1.414)\n",
    "        \n",
    "        # Attention parameters for each head\n",
    "        self.a = nn.Parameter(torch.zeros(size=(n_heads, 2*out_features, 1)))\n",
    "        nn.init.xavier_uniform_(self.a.data, gain=1.414)\n",
    "        \n",
    "        # Leaky ReLU\n",
    "        self.leakyrelu = nn.LeakyReLU(self.alpha)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        H = torch.stack([F.linear(x, self.W[i]) for i in range(self.n_heads)])\n",
    "        \n",
    "        # Prepare edge features\n",
    "        edge_src, edge_dst = edge_index\n",
    "        \n",
    "        # Initialize attention coefficients\n",
    "        N = x.size(0)\n",
    "        E = edge_src.size(0)\n",
    "        \n",
    "        # Compute attention coefficients for each head\n",
    "        attention = torch.zeros(self.n_heads, E).to(x.device)\n",
    "        \n",
    "        for h in range(self.n_heads):\n",
    "            # Compute attention coefficients\n",
    "            edge_features = torch.cat([\n",
    "                H[h, edge_src],\n",
    "                H[h, edge_dst]\n",
    "            ], dim=1)\n",
    "            \n",
    "            # Calculate attention scores\n",
    "            attention[h] = self.leakyrelu(torch.mm(edge_features, self.a[h])).squeeze(1)\n",
    "        \n",
    "        # Apply softmax to normalize attention coefficients\n",
    "        attention = F.softmax(attention, dim=1)\n",
    "        attention = F.dropout(attention, self.dropout, training=self.training)\n",
    "        \n",
    "        # Apply attention coefficients\n",
    "        out = torch.zeros(self.n_heads, N, self.out_features).to(x.device)\n",
    "        \n",
    "        for h in range(self.n_heads):\n",
    "            # Aggregate features using attention\n",
    "            for i in range(E):\n",
    "                out[h, edge_dst[i]] += attention[h, i] * H[h, edge_src[i]]\n",
    "        \n",
    "        # Combine heads\n",
    "        out = torch.mean(out, dim=0)\n",
    "        return out\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, n_heads=4):\n",
    "        super(Generator, self).__init__()\n",
    "        self.gat1 = GATLayer(input_size, hidden_size, n_heads=n_heads)\n",
    "        self.gat2 = GATLayer(hidden_size, output_size, n_heads=n_heads)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.final_activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, z, edge_index):\n",
    "        x = self.gat1(z, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return self.final_activation(x)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_heads=4):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.gat1 = GATLayer(input_size, hidden_size, n_heads=n_heads)\n",
    "        self.gat2 = GATLayer(hidden_size, 1, n_heads=n_heads)\n",
    "        self.dropout = nn.Dropout(0.6)\n",
    "        self.final_activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.gat1(x, edge_index)\n",
    "        x = F.elu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.gat2(x, edge_index)\n",
    "        return self.final_activation(x)\n",
    "\n",
    "# Visualization functions\n",
    "def plot_class_distribution(y_data, title):\n",
    "    \"\"\"Plot class distribution histogram\"\"\"\n",
    "    classes, counts = torch.unique(y_data, return_counts=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(classes.numpy(), counts.numpy())\n",
    "    plt.title(title)\n",
    "    plt.xticks([0, 1], ['Non-Fraud', 'Fraud'])\n",
    "    plt.ylabel('Count')\n",
    "    plt.show()\n",
    "\n",
    "def plot_metrics(metrics_history):\n",
    "    \"\"\"Plot training metrics over time\"\"\"\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(metrics_history['d_loss'], label='Discriminator Loss')\n",
    "    plt.plot(metrics_history['g_loss'], label='Generator Loss')\n",
    "    plt.title('Training Losses')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(metrics_history['accuracy'], label='Accuracy')\n",
    "    plt.plot(metrics_history['auc_roc'], label='AUC-ROC')\n",
    "    plt.title('Performance Metrics')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Score')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def evaluate_model(discriminator, node_features, edge_index, labels):\n",
    "    \"\"\"Evaluate model performance and print metrics\"\"\"\n",
    "    with torch.no_grad():\n",
    "        pred_probs = discriminator(node_features, edge_index)\n",
    "        pred_labels = (pred_probs > 0.5).float()\n",
    "\n",
    "    # Convert to numpy for metric calculation\n",
    "    y_true = labels.numpy()\n",
    "    y_pred = pred_labels.numpy()\n",
    "    y_prob = pred_probs.numpy()\n",
    "\n",
    "    # Calculate metrics\n",
    "    metrics = {\n",
    "        'AUC-ROC': roc_auc_score(y_true, y_prob),\n",
    "        'F1 Score': f1_score(y_true, y_pred),\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'R2 Score': r2_score(y_true, y_prob),\n",
    "        'MCC': matthews_corrcoef(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    for metric_name, value in metrics.items():\n",
    "        print(f\"{metric_name}: {value:.4f}\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def train_gan(generator, discriminator, node_features, edge_index, labels, \n",
    "              num_epochs=10, latent_size=64, batch_size=32):\n",
    "    \"\"\"Train the GAN model\"\"\"\n",
    "    \n",
    "    # Initialize optimizers\n",
    "    optimizer_g = optim.Adam(generator.parameters(), lr=0.001)\n",
    "    optimizer_d = optim.Adam(discriminator.parameters(), lr=0.001)\n",
    "    loss_fn = nn.BCELoss()\n",
    "    \n",
    "    # Get real data\n",
    "    real_data = node_features[labels == 1]\n",
    "    target_minority_class = torch.sum(labels == 0)\n",
    "    \n",
    "    # Training history\n",
    "    metrics_history = {\n",
    "        'd_loss': [], 'g_loss': [], \n",
    "        'accuracy': [], 'auc_roc': []\n",
    "    }\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        current_minority_count = torch.sum(labels == 1)\n",
    "        if current_minority_count >= target_minority_class:\n",
    "            break\n",
    "        \n",
    "        # Train discriminator\n",
    "        optimizer_d.zero_grad()\n",
    "        \n",
    "        # Real data\n",
    "        d_real = discriminator(real_data, edge_index)\n",
    "        real_labels = torch.ones(d_real.shape)\n",
    "        loss_real = loss_fn(d_real, real_labels)\n",
    "        \n",
    "        # Fake data\n",
    "        z = torch.randn(real_data.size(0), latent_size)\n",
    "        fake_data = generator(z, edge_index)\n",
    "        d_fake = discriminator(fake_data.detach(), edge_index)\n",
    "        fake_labels = torch.zeros(d_fake.shape)\n",
    "        loss_fake = loss_fn(d_fake, fake_labels)\n",
    "        \n",
    "        # Total discriminator loss\n",
    "        loss_d = loss_real + loss_fake\n",
    "        loss_d.backward()\n",
    "        optimizer_d.step()\n",
    "        \n",
    "        # Train generator\n",
    "        optimizer_g.zero_grad()\n",
    "        d_fake = discriminator(fake_data, edge_index)\n",
    "        loss_g = loss_fn(d_fake, torch.ones_like(d_fake))\n",
    "        loss_g.backward()\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        # Update dataset\n",
    "        with torch.no_grad():\n",
    "            labels = torch.cat((labels, torch.ones(fake_data.size(0), dtype=torch.long)))\n",
    "            node_features = torch.cat((node_features, fake_data))\n",
    "        \n",
    "        # Calculate metrics\n",
    "        if epoch % 2 == 0:\n",
    "            metrics = evaluate_model(discriminator, node_features, edge_index, labels)\n",
    "            metrics_history['d_loss'].append(loss_d.item())\n",
    "            metrics_history['g_loss'].append(loss_g.item())\n",
    "            metrics_history['accuracy'].append(metrics['Accuracy'])\n",
    "            metrics_history['auc_roc'].append(metrics['AUC-ROC'])\n",
    "            \n",
    "            print(f'Epoch [{epoch}/{num_epochs}]:')\n",
    "            print(f'D Loss: {loss_d.item():.4f}, G Loss: {loss_g.item():.4f}')\n",
    "            print(f'Accuracy: {metrics[\"Accuracy\"]:.4f}, AUC-ROC: {metrics[\"AUC-ROC\"]:.4f}\\n')\n",
    "    \n",
    "    return generator, discriminator, node_features, labels, metrics_history\n",
    "\n",
    "def main():\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing data...\")\n",
    "    df = pd.read_csv('creditcard/fraudTrain.csv')\n",
    "    df, node_list = preprocess(df)\n",
    "    node_features, edge_index, labels = create_graph_data(df, node_list)\n",
    "    \n",
    "    # Plot initial class distribution\n",
    "    plot_class_distribution(labels, \"Class Distribution Before Augmentation\")\n",
    "    \n",
    "    # Model parameters\n",
    "    input_size = node_features.shape[1]\n",
    "    hidden_size = 128\n",
    "    output_size = input_size\n",
    "    latent_size = 64\n",
    "    \n",
    "    # Initialize models\n",
    "    print(\"\\nInitializing models...\")\n",
    "    generator = Generator(latent_size, hidden_size, output_size)\n",
    "    discriminator = Discriminator(input_size, hidden_size)\n",
    "    \n",
    "    # Train models\n",
    "    print(\"\\nStarting training...\")\n",
    "    generator, discriminator, augmented_features, augmented_labels, metrics_history = train_gan(\n",
    "        generator, discriminator, node_features, edge_index, labels,\n",
    "        num_epochs=10, latent_size=latent_size\n",
    "    )\n",
    "    \n",
    "    # Plot final results\n",
    "    print(\"\\nPlotting final results...\")\n",
    "    plot_class_distribution(augmented_labels, \"Class Distribution After Augmentation\")\n",
    "    plot_metrics(metrics_history)\n",
    "    \n",
    "    # Final evaluation\n",
    "    print(\"\\nFinal model evaluation:\")\n",
    "    evaluate_model(discriminator, augmented_features, edge_index, augmented_labels)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
